{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaDHiQg1iW_I"
      },
      "source": [
        "<h1> Jokes Classification </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK4HQFMAia1-"
      },
      "source": [
        "<h2> 1. Prerequisites </h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dTHgF7-Gz8B",
        "outputId": "5c995a68-3f33-4100-9051-186c8b132b60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 xxhash-3.5.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets torch scikit-learn\n",
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sidkdHdQmfMc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOmpn3GDjMLv"
      },
      "source": [
        "<h2> 2. Import dataset </h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUMLe_uhjEUL",
        "outputId": "6f89ab96-6a5a-47fd-c10c-3a23e8505883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAahPqyomVsH",
        "outputId": "93d97373-a663-4dfa-8f11-c33b64ca216e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          ID Title       Category  \\\n",
            "0          5   NaN            NaN   \n",
            "1          7   NaN            NaN   \n",
            "2          8   NaN            NaN   \n",
            "3         13   NaN            NaN   \n",
            "4         15   NaN            NaN   \n",
            "...      ...   ...            ...   \n",
            "198457  3765   NaN  Miscellaneous   \n",
            "198458  3766   NaN  Miscellaneous   \n",
            "198462  3770   NaN  Miscellaneous   \n",
            "198464  3772   NaN  Miscellaneous   \n",
            "198465  3773   NaN  Miscellaneous   \n",
            "\n",
            "                                                     Body    Rating  \n",
            "0       q\\twhats o j simpsons internet address \\na\\tsl...  0.153659  \n",
            "1       how many feminists does it take to screw in a ...  0.145475  \n",
            "2       q did you hear about the dyslexic devil worshi...  0.321407  \n",
            "3       they asked the japanese visitor if they have e...  0.334060  \n",
            "4       q  what did the blind person say when given so...  0.212328  \n",
            "...                                                   ...       ...  \n",
            "198457  britain decided it was time to switch left lan...  0.800000  \n",
            "198458  examples of unclear writing sentences taken fr...  0.600000  \n",
            "198462  the pope and the queen of england are on the s...  0.800000  \n",
            "198464  letter to xerox and the reply\\n\\ndear kings of...  0.800000  \n",
            "198465  note tradewars is on online roleplaying game w...  0.600000  \n",
            "\n",
            "[134178 rows x 5 columns]\n",
            "            ID                                              Title Category  \\\n",
            "130        141                                                NaN      NaN   \n",
            "141     5tz4dd  What's the difference between a Jew in Nazi Ge...      NaN   \n",
            "142     5tz319                     I recently went to America....      NaN   \n",
            "144     5tz1pc  You hear about the University book store worke...      NaN   \n",
            "145     5tz1o1  Why is it unknown on how pterodactyls urinate ...      NaN   \n",
            "...        ...                                                ...      ...   \n",
            "407988     NaN  RIM CEO Thorsten Heins' 'Significant' Plans Fo...     TECH   \n",
            "407989     NaN  Maria Sharapova Stunned By Victoria Azarenka I...   SPORTS   \n",
            "407990     NaN  Giants Over Patriots, Jets Over Colts Among  M...   SPORTS   \n",
            "407991     NaN  Aldon Smith Arrested: 49ers Linebacker Busted ...   SPORTS   \n",
            "407992     NaN  Dwight Howard Rips Teammates After Magic Loss ...   SPORTS   \n",
            "\n",
            "                                                     Body  Rating  \n",
            "130     jack bauer can get mcdonalds breakfast after N...     0.0  \n",
            "141     pizza doesnt scream when you put it in the ove...     0.0  \n",
            "142     and being there really helped me learn about a...     0.0  \n",
            "144     he got caught trying to sell the two books to ...     0.0  \n",
            "145                               because the p is silent     0.0  \n",
            "...                                                   ...     ...  \n",
            "407988  verizon wireless and att are already promoting...     0.0  \n",
            "407989  afterward azarenka more effusive with the pres...     0.0  \n",
            "407990  leading up to super bowl xlvi the most talked ...     0.0  \n",
            "407991  correction an earlier version of this story in...     0.0  \n",
            "407992  the fivetime allstar center tore into his team...     0.0  \n",
            "\n",
            "[249338 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "# Positive Examples (Keep only entries where the Rating column is not null)\n",
        "\n",
        "normalized_jester_df = pd.read_csv('/content/drive/MyDrive/Proiect NLP/Datasets/Preprocessed-Datasets/Positive-Examples/jester/normalized_jester.csv')\n",
        "normalized_reddit_jokes_df = pd.read_csv('/content/drive/MyDrive/Proiect NLP/Datasets/Preprocessed-Datasets/Positive-Examples/joke-dataset/normalized_reddit_jokes.csv')\n",
        "normalized_stupidstuff_df = pd.read_csv('/content/drive/MyDrive/Proiect NLP/Datasets/Preprocessed-Datasets/Positive-Examples/joke-dataset/normalized_stupidstuff.csv')\n",
        "\n",
        "normalized_jester_df = normalized_jester_df[normalized_jester_df['Rating'].notna()]\n",
        "normalized_reddit_jokes_df = normalized_reddit_jokes_df[normalized_reddit_jokes_df['Rating'].notna()]\n",
        "normalized_stupidstuff_df = normalized_stupidstuff_df[normalized_stupidstuff_df['Rating'].notna()]\n",
        "\n",
        "# Negative Examples (All of them, put 0 in the Rating column)\n",
        "\n",
        "news_category_dataset_df = pd.read_csv('/content/drive/MyDrive/Proiect NLP/Datasets/Preprocessed-Datasets/Negative-Examples/News_Category_Dataset_v3/News_Category_Dataset_v3.csv')\n",
        "news_category_dataset_df['Rating'] = news_category_dataset_df['Rating'].fillna(0.0)\n",
        "\n",
        "df = pd.concat([normalized_jester_df, normalized_reddit_jokes_df, normalized_stupidstuff_df, news_category_dataset_df], ignore_index=True)\n",
        "df = df.dropna(subset=['Body'])\n",
        "df = df[df['Body'].str.strip() != '']\n",
        "\n",
        "def preprocessed_sample(sample):\n",
        "  sample = str(sample)\n",
        "  sample = re.sub(r'[^a-zA-Z0-9\\s]', '', sample) # Only letters (lowercase and uppercase) + digits\n",
        "  sample = sample.lower() # Everything lowercase\n",
        "  sample = re.sub(r'\\d+', 'NUMBER', sample) # Replace all numerical values with a common label.\n",
        "  return sample\n",
        "\n",
        "df['Body'] = df['Body'].apply(preprocessed_sample)\n",
        "print(df[df['Rating'] != 0.0])\n",
        "print(df[df['Rating'] == 0.0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLlrVLpEjPrJ"
      },
      "source": [
        "<h2> 3. Train / Val split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yegVFyVjLMI",
        "outputId": "dafec11a-7aef-46aa-f688-a432e2f405cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train zero: 159576 Train not zero: 85873\n",
            "Val zero: 39894 Val not zero: 21469\n",
            "Test zero: 49868 Test not zero: 26836\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from transformers import (\n",
        "    BertTokenizerFast,\n",
        "    BertForSequenceClassification,\n",
        ")\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=1,\n",
        "    problem_type=\"regression\"\n",
        ")\n",
        "\n",
        "TEST_PERCENTAGE_FROM_ALL = 0.2\n",
        "VAL_PERCENTAGE_FROM_TRAIN = 0.2\n",
        "\n",
        "\n",
        "X_train_zero = df[df['Rating'] == 0.0]['Body']\n",
        "y_train_zero = df[df['Rating'] == 0.0]['Rating']\n",
        "\n",
        "X_train_notzero = df[df['Rating'] != 0.0]['Body']\n",
        "y_train_notzero = df[df['Rating'] != 0.0]['Rating']\n",
        "\n",
        "X_train_zero, X_test_zero, y_train_zero, y_test_zero = train_test_split(X_train_zero, y_train_zero, test_size=TEST_PERCENTAGE_FROM_ALL, random_state=17)\n",
        "X_train_zero, X_val_zero, y_train_zero, y_val_zero = train_test_split(X_train_zero, y_train_zero, test_size=VAL_PERCENTAGE_FROM_TRAIN, random_state=17)\n",
        "\n",
        "X_train_notzero, X_test_notzero, y_train_notzero, y_test_notzero = train_test_split(X_train_notzero, y_train_notzero, test_size=TEST_PERCENTAGE_FROM_ALL, random_state=17)\n",
        "X_train_notzero, X_val_notzero, y_train_notzero, y_val_notzero = train_test_split(X_train_notzero, y_train_notzero, test_size=VAL_PERCENTAGE_FROM_TRAIN, random_state=17)\n",
        "\n",
        "X_train = pd.concat([X_train_zero, X_train_notzero])\n",
        "y_train = pd.concat([y_train_zero, y_train_notzero])\n",
        "\n",
        "X_val = pd.concat([X_val_zero, X_val_notzero])\n",
        "y_val = pd.concat([y_val_zero, y_val_notzero])\n",
        "\n",
        "X_test = pd.concat([X_test_zero, X_test_notzero])\n",
        "y_test = pd.concat([y_test_zero, y_test_notzero])\n",
        "\n",
        "\n",
        "train_enc = tokenizer(\n",
        "    X_train.tolist(),\n",
        "    truncation=True,\n",
        "    padding=\"max_length\",\n",
        "    max_length=64,\n",
        ")\n",
        "val_enc = tokenizer(\n",
        "    X_val.tolist(),\n",
        "    truncation=True,\n",
        "    padding=\"max_length\",\n",
        "    max_length=64,\n",
        ")\n",
        "test_enc = tokenizer(\n",
        "    X_test.tolist(),\n",
        "    truncation=True,\n",
        "    padding=\"max_length\",\n",
        "    max_length=64,\n",
        ")\n",
        "print('Train zero:', X_train_zero.shape[0], 'Train not zero:', X_train_notzero.shape[0])\n",
        "print('Val zero:', X_val_zero.shape[0], 'Val not zero:', X_val_notzero.shape[0])\n",
        "print('Test zero:', X_test_zero.shape[0], 'Test not zero:', X_test_notzero.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voczJ7F2jo6q"
      },
      "source": [
        "<h2> 4. Dataset Creation <h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1vKoDlhMjsQM"
      },
      "outputs": [],
      "source": [
        "class TextRegressionDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = torch.tensor(labels.tolist(), dtype=torch.float)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = self.labels[idx].unsqueeze(0)\n",
        "        return item\n",
        "train_dataset = TextRegressionDataset(train_enc, y_train)\n",
        "val_dataset   = TextRegressionDataset(val_enc,   y_val)\n",
        "test_dataset  = TextRegressionDataset(test_enc,  y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eTlr5_C2jyou",
        "outputId": "48deffa3-1a27-4304-db57-4b03f0e6b7b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdragos-ciobanu232\u001b[0m (\u001b[33mdragos-ciobanu232-university-of-bucharest\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250510_192945-c0uq051w</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dragos-ciobanu232-university-of-bucharest/huggingface/runs/c0uq051w' target=\"_blank\">./bart_regression</a></strong> to <a href='https://wandb.ai/dragos-ciobanu232-university-of-bucharest/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dragos-ciobanu232-university-of-bucharest/huggingface' target=\"_blank\">https://wandb.ai/dragos-ciobanu232-university-of-bucharest/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dragos-ciobanu232-university-of-bucharest/huggingface/runs/c0uq051w' target=\"_blank\">https://wandb.ai/dragos-ciobanu232-university-of-bucharest/huggingface/runs/c0uq051w</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='23013' max='23013' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [23013/23013 21:38, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.011500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.006000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.005800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.005400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.005800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.006700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.004900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.008200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.005000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.006000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.003400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.005300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.006900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.004900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.005200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.007900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.004800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.006300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.004600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.003400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.006400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.006700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.005700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.002400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.005200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.006600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.006100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.006100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.005900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>0.005100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.004600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2950</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.006500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3050</td>\n",
              "      <td>0.007500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3150</td>\n",
              "      <td>0.006600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3250</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3350</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3450</td>\n",
              "      <td>0.004900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.007100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3550</td>\n",
              "      <td>0.004900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3650</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3850</td>\n",
              "      <td>0.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.006400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3950</td>\n",
              "      <td>0.006000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4050</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4150</td>\n",
              "      <td>0.005400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4250</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4350</td>\n",
              "      <td>0.005000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.004800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4450</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4550</td>\n",
              "      <td>0.004600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4650</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4750</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4850</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4950</td>\n",
              "      <td>0.003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5050</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5150</td>\n",
              "      <td>0.006600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.005400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5250</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5350</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5450</td>\n",
              "      <td>0.008600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.006500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5550</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5650</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5750</td>\n",
              "      <td>0.005300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.005700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5850</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5950</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6050</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6150</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6250</td>\n",
              "      <td>0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6350</td>\n",
              "      <td>0.005000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6450</td>\n",
              "      <td>0.002800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6550</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6650</td>\n",
              "      <td>0.005200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6750</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6850</td>\n",
              "      <td>0.004600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6950</td>\n",
              "      <td>0.002700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.004600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7050</td>\n",
              "      <td>0.003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.006300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7150</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7250</td>\n",
              "      <td>0.004600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.004900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7350</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.005100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7450</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7550</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.006500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7650</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7750</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7850</td>\n",
              "      <td>0.004600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.007000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7950</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.004600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8050</td>\n",
              "      <td>0.005400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8150</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.008000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8250</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8350</td>\n",
              "      <td>0.004800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8450</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8550</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.005300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8650</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8750</td>\n",
              "      <td>0.003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8850</td>\n",
              "      <td>0.006300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8950</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9050</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.005900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9150</td>\n",
              "      <td>0.005800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9250</td>\n",
              "      <td>0.005400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9350</td>\n",
              "      <td>0.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.005000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9450</td>\n",
              "      <td>0.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.006600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9550</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9650</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9700</td>\n",
              "      <td>0.005200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9750</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9850</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9900</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9950</td>\n",
              "      <td>0.004600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10050</td>\n",
              "      <td>0.006000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10100</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10150</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10250</td>\n",
              "      <td>0.003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10300</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10350</td>\n",
              "      <td>0.003400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10400</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10450</td>\n",
              "      <td>0.003400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.001900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10550</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10600</td>\n",
              "      <td>0.005000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10650</td>\n",
              "      <td>0.001700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10700</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10750</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10800</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10850</td>\n",
              "      <td>0.005800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10900</td>\n",
              "      <td>0.006400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10950</td>\n",
              "      <td>0.005400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.006200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11050</td>\n",
              "      <td>0.002700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11100</td>\n",
              "      <td>0.003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11150</td>\n",
              "      <td>0.003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11200</td>\n",
              "      <td>0.002800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11250</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11300</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11350</td>\n",
              "      <td>0.004900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11400</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11450</td>\n",
              "      <td>0.004600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11550</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11600</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11650</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11700</td>\n",
              "      <td>0.005700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11750</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11800</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11850</td>\n",
              "      <td>0.003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11900</td>\n",
              "      <td>0.004600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11950</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.002800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12050</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12100</td>\n",
              "      <td>0.005700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12150</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12200</td>\n",
              "      <td>0.004900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12250</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12300</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12350</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12400</td>\n",
              "      <td>0.004600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12450</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12550</td>\n",
              "      <td>0.005800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12600</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12650</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12700</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12750</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12800</td>\n",
              "      <td>0.003400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12850</td>\n",
              "      <td>0.004800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12900</td>\n",
              "      <td>0.003400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12950</td>\n",
              "      <td>0.005000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13050</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13100</td>\n",
              "      <td>0.004800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13150</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13200</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13250</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13300</td>\n",
              "      <td>0.004600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13350</td>\n",
              "      <td>0.005100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13400</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13450</td>\n",
              "      <td>0.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13550</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13600</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13650</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13700</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13750</td>\n",
              "      <td>0.005200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13800</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13850</td>\n",
              "      <td>0.004900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13900</td>\n",
              "      <td>0.005700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13950</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14050</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14100</td>\n",
              "      <td>0.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14150</td>\n",
              "      <td>0.005100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14200</td>\n",
              "      <td>0.004600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14250</td>\n",
              "      <td>0.005700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14300</td>\n",
              "      <td>0.006400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14350</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14400</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14450</td>\n",
              "      <td>0.006500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14550</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14600</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14650</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14700</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14750</td>\n",
              "      <td>0.005100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14800</td>\n",
              "      <td>0.004800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14850</td>\n",
              "      <td>0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14900</td>\n",
              "      <td>0.003400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14950</td>\n",
              "      <td>0.005100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.005000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15050</td>\n",
              "      <td>0.003400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15100</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15150</td>\n",
              "      <td>0.006400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15200</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15250</td>\n",
              "      <td>0.006000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15300</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15350</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15400</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15450</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15550</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15600</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15650</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15700</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15750</td>\n",
              "      <td>0.003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15800</td>\n",
              "      <td>0.005200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15850</td>\n",
              "      <td>0.005000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15900</td>\n",
              "      <td>0.003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15950</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16050</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16100</td>\n",
              "      <td>0.003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16150</td>\n",
              "      <td>0.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16200</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16250</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16300</td>\n",
              "      <td>0.002700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16350</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16400</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16450</td>\n",
              "      <td>0.001700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16500</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16550</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16600</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16650</td>\n",
              "      <td>0.002800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16700</td>\n",
              "      <td>0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16750</td>\n",
              "      <td>0.004600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16800</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16850</td>\n",
              "      <td>0.005300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16900</td>\n",
              "      <td>0.003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16950</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17050</td>\n",
              "      <td>0.002400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17100</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17150</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17200</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17250</td>\n",
              "      <td>0.005800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17300</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17350</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17400</td>\n",
              "      <td>0.002400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17450</td>\n",
              "      <td>0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17500</td>\n",
              "      <td>0.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17550</td>\n",
              "      <td>0.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17600</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17650</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17700</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17750</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17800</td>\n",
              "      <td>0.003400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17850</td>\n",
              "      <td>0.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17900</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17950</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18050</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18100</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18150</td>\n",
              "      <td>0.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18200</td>\n",
              "      <td>0.003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18250</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18300</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18350</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18400</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18450</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18500</td>\n",
              "      <td>0.002400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18550</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18600</td>\n",
              "      <td>0.002800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18650</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18700</td>\n",
              "      <td>0.002800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18750</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18800</td>\n",
              "      <td>0.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18850</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18900</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18950</td>\n",
              "      <td>0.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19000</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19050</td>\n",
              "      <td>0.003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19100</td>\n",
              "      <td>0.003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19150</td>\n",
              "      <td>0.003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19200</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19250</td>\n",
              "      <td>0.004600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19300</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19350</td>\n",
              "      <td>0.003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19400</td>\n",
              "      <td>0.004900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19450</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19500</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19550</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19600</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19650</td>\n",
              "      <td>0.003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19700</td>\n",
              "      <td>0.003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19750</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19800</td>\n",
              "      <td>0.002800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19850</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19900</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19950</td>\n",
              "      <td>0.001900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20050</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20100</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20150</td>\n",
              "      <td>0.004800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20200</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20250</td>\n",
              "      <td>0.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20300</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20350</td>\n",
              "      <td>0.002400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20400</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20450</td>\n",
              "      <td>0.001700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20500</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20550</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20600</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20650</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20700</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20750</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20800</td>\n",
              "      <td>0.005100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20850</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20900</td>\n",
              "      <td>0.002800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20950</td>\n",
              "      <td>0.002400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21000</td>\n",
              "      <td>0.004600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21050</td>\n",
              "      <td>0.003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21100</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21150</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21200</td>\n",
              "      <td>0.001900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21250</td>\n",
              "      <td>0.004900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21300</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21350</td>\n",
              "      <td>0.001700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21400</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21450</td>\n",
              "      <td>0.005100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21500</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21550</td>\n",
              "      <td>0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21600</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21650</td>\n",
              "      <td>0.002700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21700</td>\n",
              "      <td>0.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21750</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21800</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21850</td>\n",
              "      <td>0.005300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21900</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21950</td>\n",
              "      <td>0.001700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22000</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22050</td>\n",
              "      <td>0.005300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22100</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22150</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22200</td>\n",
              "      <td>0.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22250</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22300</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22350</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22400</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22450</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22500</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22550</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22600</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22650</td>\n",
              "      <td>0.003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22700</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22750</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22800</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22850</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22900</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22950</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23000</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=23013, training_loss=0.004038063021174301, metrics={'train_runtime': 1335.3459, 'train_samples_per_second': 551.428, 'train_steps_per_second': 17.234, 'total_flos': 2.421741209482253e+16, 'train_loss': 0.004038063021174301, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bart_regression\",\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    eval_steps=500,\n",
        "    logging_steps=50,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    optim=\"adamw_torch\",\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    if hasattr(eval_pred, \"predictions\"):\n",
        "        preds = eval_pred.predictions\n",
        "        labels = eval_pred.label_ids\n",
        "    else:\n",
        "        preds, labels = eval_pred\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    preds = preds.squeeze()\n",
        "    labels = labels.squeeze()\n",
        "    mse = mean_squared_error(labels, preds)\n",
        "    return {\n",
        "        \"mse\": mse,\n",
        "        \"rmse\": mse ** 0.5,\n",
        "        \"mae\": mean_absolute_error(labels, preds),\n",
        "    }\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIk2wibpkFyo"
      },
      "source": [
        "<h2> 6. Evaluate </h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "V-dXNRCfCACn",
        "outputId": "41aa830c-a6d5-47fe-f757-77e3799c3dad"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2397' max='2397' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2397/2397 00:39]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test metrics: {'eval_loss': 0.0037757863756269217, 'eval_mse': 0.0037757863756269217, 'eval_rmse': 0.06144742773808291, 'eval_mae': 0.010927475988864899, 'eval_runtime': 39.1246, 'eval_samples_per_second': 1960.504, 'eval_steps_per_second': 61.266, 'epoch': 3.0}\n"
          ]
        }
      ],
      "source": [
        "test_metrics = trainer.evaluate(eval_dataset=test_dataset)\n",
        "\n",
        "print(\"Test metrics:\",       test_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uh4LSOzBGt7p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7ec01c7e-4924-4f50-a0b1-1ffb3777f1a8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ],
      "source": [
        "pred_output = trainer.predict(test_dataset)\n",
        "preds = pred_output.predictions\n",
        "if isinstance(preds, tuple):\n",
        "    preds = preds[0]\n",
        "preds = preds.squeeze()\n",
        "labels = pred_output.label_ids.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        },
        "id": "QfM4ezGlOUAb",
        "outputId": "562034a7-3d76-442e-ec8e-e1c249b11685"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thr 0.00 | P=0.697  R=0.692  F1(weighted)=0.631\n",
            "thr 0.10 | P=0.729  R=0.657  F1(weighted)=0.530\n",
            "thr 0.20 | P=0.733  R=0.654  F1(weighted)=0.522\n",
            "thr 0.30 | P=0.735  R=0.653  F1(weighted)=0.519\n",
            "thr 0.40 | P=0.735  R=0.652  F1(weighted)=0.518\n",
            "thr 0.50 | P=0.735  R=0.652  F1(weighted)=0.517\n",
            "thr 0.60 | P=0.749  R=0.650  F1(weighted)=0.513\n",
            "thr 0.70 | P=0.423  R=0.650  F1(weighted)=0.512\n",
            "thr 0.80 | P=0.423  R=0.650  F1(weighted)=0.512\n",
            "thr 0.90 | P=0.423  R=0.650  F1(weighted)=0.512\n",
            "thr 1.00 | P=0.423  R=0.650  F1(weighted)=0.512\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAGJCAYAAABmacmGAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAZURJREFUeJzt3XlcVPX+P/DXmWEWdtlBRFFQAXcxCDfcabl5rd+9eVvN0srktnAzNb9X1EpbTL23682yzLrlzbLN0msSiCuuaGmyqKCYyi77Nsyc3x/A5MigHBw4M/B6Ph7zkPnMWd7n8Mnm5eeczxFEURRBREREREREt0QhdwFERERERESdAcMVERERERGRBTBcERERERERWQDDFRERERERkQUwXBEREREREVkAwxUREREREZEFMFwRERERERFZAMMVERERERGRBTBcERERERERWQDDFRFRJ3Tx4kVotVrs37+/w/Y5btw4jBs3rs3rDhw40LIFSbRkyRIIgmB8r9PpEBAQgH//+98yVnVj1nDertUe9QiCgCVLltx0uet/f0REcmC4IiLqIBs3boQgCGZfCxYsMC63c+dOPPHEExg4cCCUSiUCAwMl72vZsmWIjIzEqFGjLHgE8rt8+TKWLFmCEydOtPu+VCoV4uLi8Nprr6Gmpqbd99eSjjxmIiK6NXZyF0BE1NUsW7YMvXv3Nmm79l/7N23ahM2bN2P48OHo3r275O0XFBTg448/xscff3zLtUqxc+fOdt/H5cuXsXTpUgQGBmLo0KHtvr+ZM2diwYIF2LRpEx5//PF23585HX3MRETUdgxXREQd7M4778SIESNa/Hz58uVYv349VCoV/vCHP+DUqVOStv/pp5/Czs4O99xzz62WKolare7Q/XWEbt26YcqUKdi4caNs4aq91NTUQK1WQ6HgRSxERJbCv1GJiKxM9+7doVKp2rz+t99+i8jISDg5ORnb/vnPf0KpVKKkpMTY9vbbb0MQBMTFxRnb9Ho9nJ2dMX/+fGObwWDAmjVrMGDAAGi1Wvj4+OCpp57C1atXTfZr7p6rCxcuYOrUqXB0dIS3tzdeeOEF/PjjjxAEAcnJyc1qP336NMaPHw8HBwf4+/vjzTffNH6WnJyM2267DUDDiFLTJZUbN240LnPo0CHccccdcHV1hYODA6Kjo83ed7Zv3z7cdttt0Gq1CAoKwnvvvdfi+Zw8eTL27duH4uLiFpfJy8uDnZ0dli5d2uyzjIwMCIKAf/3rXwAa7uVaunQp+vbtC61WCw8PD4wePRoJCQnN1m3NMd/svDVtRxAEfP755/i///s/+Pv7w8HBAWVlZa0+b+Xl5Xj++ecRGBgIjUYDb29vTJ48Gampqc3qvlk9AJCfn48nnngCPj4+0Gq1GDJkSKtHW6X8/oiIOhJHroiIOlhpaSkKCwtN2jw9PS2ybZ1OhyNHjmDOnDkm7WPGjIHBYMC+ffvwhz/8AQCwd+9eKBQK7N2717jc8ePHUVFRgbFjxxrbnnrqKWzcuBEzZ87Es88+i+zsbPzrX//C8ePHsX///haDYGVlJSZMmIArV67gueeeg6+vLzZt2oRdu3aZXf7q1au44447cN999+H+++/Hli1bMH/+fAwaNAh33nknQkNDsWzZMixevBhPPvkkxowZAwAYOXIkACApKQl33nknwsPDER8fD4VCgY8++ggTJkzA3r17ERERAQA4efIkpkyZAi8vLyxZsgT19fWIj4+Hj4+P2brCw8MhiiIOHDhgPHfX8/HxQXR0NL744gvEx8ebfLZ582YolUr8+c9/BtAw8cKKFSswa9YsREREoKysDEePHkVqaiomT55ssu7Njrk15+1ar7zyCtRqNV588UXU1tZCrVa3+rw9/fTT2LJlC2JjYxEWFoaioiLs27cPaWlpGD58uKR6qqurMW7cOJw9exaxsbHo3bs3vvzySzz22GMoKSnBc889Z/Y8t+X3R0TUoUQiIuoQH330kQjA7Ksld999t9irV69W7+Ps2bMiAPGdd94xadfr9aKLi4v40ksviaIoigaDQfTw8BD//Oc/i0qlUiwvLxdFURRXrVolKhQK8erVq6IoiuLevXtFAOJnn31msr0dO3Y0a4+Ojhajo6ON799++20RgPjtt98a26qrq8WQkBARgLhr1y6TdQGIn3zyibGttrZW9PX1Ff/f//t/xrYjR46IAMSPPvrIpB6DwSD27dtXjImJEQ0Gg7G9qqpK7N27tzh58mRj27Rp00StViteuHDB2Hb69GlRqVSa/V1cvnxZBCC+8cYbzT671nvvvScCEE+ePGnSHhYWJk6YMMH4fsiQIeLdd999w21dq6VjFsXWn7ddu3aJAMQ+ffqIVVVVxnYp583V1VWcO3fuDWttbT1r1qwRAYiffvqpsa2urk6MiooSnZycxLKyMmM7ADE+Pt74Xurvj4ioI/GyQCKiDrZ27VokJCSYvCylqKgIAODm5mbSrlAoMHLkSOzZswcAkJaWhqKiIixYsACiKCIlJQVAw2jWwIED0a1bNwDAl19+CVdXV0yePBmFhYXGV3h4OJycnFochQKAHTt2wN/fH1OnTjW2abVazJ492+zyTk5OePjhh43v1Wo1IiIikJWVddPjPnHiBM6cOYMHH3wQRUVFxjorKysxceJE7NmzBwaDAXq9Hj/++COmTZuGnj17GtcPDQ1FTEyM2W03ncvrRxuvd99998HOzg6bN282tp06dQqnT5/G9OnTjW3dunXDr7/+ijNnztz0uFpDynmbMWMG7O3tje9be96a6j506BAuX758y/Vs374dvr6+eOCBB4xtKpUKzz77LCoqKrB7926z227L74+IqCMxXBERdbCIiAhMmjTJ5GVpoig2axszZgyOHTuG6upq7N27F35+fhg+fDiGDBlivDRw3759xkvPAODMmTMoLS2Ft7c3vLy8TF4VFRXIz89vsYYLFy4gKCio2bOHgoODzS7fo0ePZsu6ubk1u7fLnKagMmPGjGZ1fvDBB6itrUVpaSkKCgpQXV2Nvn37NttG//79zW676Vze7BlKnp6emDhxIr744gtj2+bNm2FnZ4f77rvP2LZs2TKUlJSgX79+GDRoEObNm4dffvnlpsfYEinn7fpZKlt73gDgzTffxKlTpxAQEICIiAgsWbLEbIBrTT0XLlxA3759m02mERoaavzcnLb8/oiIOhLvuSIi6kQ8PDwAwOwX69GjR0On0yElJQV79+41hqgxY8Zg7969SE9PR0FBgUm4MhgM8Pb2xmeffWZ2f15eXharXalUmm03FxSv1zS68tZbb7U4XbmTkxNqa2sl19V0LltzX9xf/vIXzJw5EydOnMDQoUPxxRdfYOLEiSbrjh07FufOncN3332HnTt34oMPPsDq1auxbt06zJo1S3J9Us7btaNWQOvPGwDcf//9GDNmDL755hvs3LkTb731Ft544w18/fXXJvd23crvkYjI1jFcERF1Ij179oS9vT2ys7ObfRYREQG1Wo29e/di7969mDdvHoCGL/vr169HYmKi8X2ToKAg/PTTTxg1alSzL+Y306tXL5w+fRqiKJqMZJw9e7Ythwag5dGjoKAgAICLi8sNRwK9vLxgb29v9pK8jIwMs+s0ncumUZUbmTZtGp566injpYGZmZlYuHBhs+Xc3d0xc+ZMzJw50ziByJIlS8yGq5uNmN2K1p63Jn5+fnjmmWfwzDPPID8/H8OHD8drr73WbOKMm+nVqxd++eUXGAwGk9Gr9PR04+fmtOX3R0TUkXhZIBFRJ6JSqTBixAgcPXq02WdarRa33XYb/vvf/yInJ8dk5Kq6uhr//Oc/ERQUBD8/P+M6999/P/R6PV555ZVm26uvrzeZ2v16MTExuHTpErZu3Wpsq6mpwfr169t8fI6OjgDQbL/h4eEICgrCypUrUVFR0Wy9goICAA2jKjExMfj222+Rk5Nj/DwtLQ0//vij2X0eO3YMgiAgKirqpvV169YNMTEx+OKLL/D5559DrVZj2rRpJss03RfXxMnJCcHBwS2OqrV0zJbQ2vOm1+uNlwc28fb2Rvfu3ds0GnjXXXchNzfX5P60+vp6vPPOO3ByckJ0dLTZ9dry+yMi6kgcuSIisjK//PKLMZCcPXsWpaWlePXVVwEAQ4YMuenDgf/4xz9i0aJFKCsrg4uLi8lnY8aMweuvvw5XV1cMGjQIQMOX5P79+yMjIwOPPfaYyfLR0dF46qmnsGLFCpw4cQJTpkyBSqXCmTNn8OWXX+If//gH/vSnP5mt46mnnsK//vUvPPDAA3juuefg5+eHzz77DFqtFkDbRmSCgoLQrVs3rFu3Ds7OznB0dERkZCR69+6NDz74AHfeeScGDBiAmTNnwt/fH5cuXcKuXbvg4uKC77//HgCwdOlS7NixA2PGjMEzzzxj/FI/YMAAs/c+JSQkYNSoUcZLLm9m+vTpePjhh/Hvf/8bMTExxslBmoSFhWHcuHEIDw+Hu7s7jh49apziXOox3yqFQtGq81ZeXo4ePXrgT3/6E4YMGQInJyf89NNPOHLkCN5++23J+33yySfx3nvv4bHHHsOxY8cQGBiILVu2YP/+/VizZg2cnZ1bXFfq74+IqEPJOFMhEVGX0jQV+5EjR1q1nLnXjBkzbrqfvLw80c7OTvzPf/7T7LNt27aJAMQ777zTpH3WrFkiAPHDDz80u833339fDA8PF+3t7UVnZ2dx0KBB4ksvvSRevnzZuMz1U7GLoihmZWWJd999t2hvby96eXmJf/vb38SvvvpKBCAePHjQZN0BAwY02++MGTOaTUX/3XffiWFhYaKdnV2zKcqPHz8u3nfffaKHh4eo0WjEXr16iffff7+YmJhoso3du3eL4eHholqtFvv06SOuW7dOjI+PbzaVd0lJiahWq8UPPvjA7Hkxp6ysTLS3t2821XiTV199VYyIiBC7desm2tvbiyEhIeJrr70m1tXVtbjNlo65teetaSr2L7/80uz2b3beamtrxXnz5olDhgwRnZ2dRUdHR3HIkCHiv//9b5PtSPk95uXliTNnzhQ9PT1FtVotDho0yOx087huKnZRbP3vj4ioowmiyDtMiYg6myeeeAKZmZkmDwi2FmvWrMELL7yA3377Df7+/nKXc0Nr1qzBm2++iXPnzkm+54yIiLoehisiok4oJycH/fr1Q2JiIkaNGiVbHdXV1SahpKamBsOGDYNer0dmZqZsdbWGTqdDUFAQFixYgGeeeUbucoiIyAbwnisiok6oZ8+eqKmpkbsM3HfffejZsyeGDh2K0tJSfPrpp0hPT29xandrolKpTCZNICIiuhmGKyIiajcxMTH44IMP8Nlnn0Gv1yMsLAyff/45pk+fLndpREREFsfLAomIiIiIiCyAz7kiIiIiIiKyAIYrIiIiIiIiC+A9V2YYDAZcvnwZzs7ObXrIJRERERERdQ6iKKK8vBzdu3eHQnHjsSmGKzMuX76MgIAAucsgIiIiIiIrcfHiRfTo0eOGyzBcmeHs7Ayg4QS6uLjIWotOp8POnTsxZcoUqFQqWWsh28A+Q1Kxz5BU7DMkFfsMSWVNfaasrAwBAQHGjHAjDFdmNF0K6OLiYhXhysHBAS4uLrJ3LLIN7DMkFfsMScU+Q1Kxz5BU1thnWnO7ECe0ICIiIiIisgCGKyIiIiIiIgtguCIiIiIiIrIAhisiIiIiIiILYLgiIiIiIiKyAIYrIiIiIiIiC2C4smJ6g4hD2cU4VijgUHYx9AZR7pKIiIiIiKgFfM6Vldpx6gqWfn8aV0prACjxyZmj8HPVIv6eMNwx0E/u8oiIiIiI6DocubJCO05dwZxPUxuD1e9yS2sw59NU7Dh1RabKiIiIiIioJQxXVkZvELH0+9MwdwFgU9vS70/zEkEiIiIiIivDcGVlDmcXNxuxupYI4EppDQ5nF3dcUUREREREdFMMV1Ymv7zlYNWW5YiIiIiIqGMwXFkZb2etRZcjIiIiIqKOwXBlZSJ6u8PPVQuhhc8FAH6uWkT0du/IsoiIiIiI6CYYrqyMUiEg/p4wAGgxYMXfEwaloqVPiYiIiIhIDgxXVuiOgX549+Hh8HU1vfRPrRTw7sPD+ZwrIiIiIiIrxIcIW6k7BvphcpgvUs7m4+vEQ/j6ghL1BhG39/GQuzQiIiIiIjKDI1dWTKkQENnbHdHdRfT1doRBBHZnFshdFhERERERmcFwZSPG9/cCAOxKz5e5EiIiIiIiMofhykY0havkzALU6w0yV0NERERERNdjuLIRQ3u4opuDCiVVOhy/WCJ3OUREREREdB2GKxthp1Qgul/D6FViGi8NJCIiIiKyNgxXNmRCiDcA3ndFRERERGSNGK5sSHQ/LygVAjLyynGxuErucoiIiIiI6BoMVzakm4Ma4b3cAAC7Mjh6RURERERkTRiubMzExksDed8VEREREZF1YbiyMU33XaVkFaGqrl7maoiIiIiIqAnDlY0J9nZCgLs96uoN2H+2SO5yiIiIiIioEcOVjREEARNDfAAASel5MldDRERERERNGK5s0IRr7rsSRVHmaoiIiIiICGC4skmRfdzhoFYiv7wWv14uk7scIiIiIiICw5VN0tgpMTrYEwBnDSQiIiIishayh6u1a9ciMDAQWq0WkZGROHz48A2XLykpwdy5c+Hn5weNRoN+/fph+/btxs9XrFiB2267Dc7OzvD29sa0adOQkZHR3ofR4SaGNlwamMTnXRERERERWQVZw9XmzZsRFxeH+Ph4pKamYsiQIYiJiUF+vvnAUFdXh8mTJ+P8+fPYsmULMjIysH79evj7+xuX2b17N+bOnYuDBw8iISEBOp0OU6ZMQWVlZUcdVocY378hXP18sQQF5bUyV0NERERERHZy7nzVqlWYPXs2Zs6cCQBYt24dtm3bhg0bNmDBggXNlt+wYQOKi4tx4MABqFQqAEBgYKDJMjt27DB5v3HjRnh7e+PYsWMYO3Zs+xyIDLxdtBjcwxW//FaKXRn5uH9EgNwlERERERF1abKFq7q6Ohw7dgwLFy40tikUCkyaNAkpKSlm19m6dSuioqIwd+5cfPfdd/Dy8sKDDz6I+fPnQ6lUml2ntLQUAODu7t5iLbW1tait/X30p6ysYZIInU4HnU4n+dgsqWn/5uqI7uuBX34rxU+nc3HvEN+OLo2s1I36DJE57DMkFfsMScU+Q1JZU5+RUoNs4aqwsBB6vR4+Pj4m7T4+PkhPTze7TlZWFpKSkvDQQw9h+/btOHv2LJ555hnodDrEx8c3W95gMOD555/HqFGjMHDgwBZrWbFiBZYuXdqsfefOnXBwcJB4ZO0jISGhWZu6AgDssDs9D1t/2A472e+gI2tirs8Q3Qj7DEnFPkNSsc+QVNbQZ6qqqlq9rKyXBUplMBjg7e2N999/H0qlEuHh4bh06RLeeusts+Fq7ty5OHXqFPbt23fD7S5cuBBxcXHG92VlZQgICMCUKVPg4uJi8eOQQqfTISEhAZMnTzZeCtnEYBDxSfZuFFTUwSM0EqOCPGSqkqzJjfoMkTnsMyQV+wxJxT5DUllTn2m6qq01ZAtXnp6eUCqVyMvLM2nPy8uDr6/5S9z8/PygUqlMLgEMDQ1Fbm4u6urqoFarje2xsbH44YcfsGfPHvTo0eOGtWg0Gmg0mmbtKpVK9l9mk5ZqmRDig81HL2L3mSKMC+GlgfQ7a+q/ZBvYZ0gq9hmSin2GpLKGPiNl/7JdSKZWqxEeHo7ExERjm8FgQGJiIqKiosyuM2rUKJw9exYGg8HYlpmZCT8/P2OwEkURsbGx+Oabb5CUlITevXu374HIbELjlOyJafkQRVHmaoiIiIiIui5Z79KJi4vD+vXr8fHHHyMtLQ1z5sxBZWWlcfbARx991GTCizlz5qC4uBjPPfccMjMzsW3bNixfvhxz5841LjN37lx8+umn2LRpE5ydnZGbm4vc3FxUV1d3+PF1hNHBnlArFcgprsK5gs413TwRERERkS2R9Z6r6dOno6CgAIsXL0Zubi6GDh2KHTt2GCe5yMnJgULxe/4LCAjAjz/+iBdeeAGDBw+Gv78/nnvuOcyfP9+4zLvvvgsAGDdunMm+PvroIzz22GPtfkwdzVFjh8g+7th7phC70vMR7O0kd0lERERERF2S7BNaxMbGIjY21uxnycnJzdqioqJw8ODBFrfXFS+Nmxjijb1nCpGYnofZY/vIXQ4RERERUZfEybs7gQkhDSN9R85fRWm1/M8CICIiIiLqihiuOoGeHg7o6+0EvUHEnswCucshIiIiIuqSGK46iQkhDbMGJqXny1wJEREREVHXxHDVSTSFq+SMfOgNXe++MyIiIiIiuTFcdRLhvdzgorXD1SodTly8Knc5RERERERdDsNVJ2GnVGBc/98fKExERERERB2L4aoT4X1XRERERETyYbjqRKL7eUEhAOm55bhUUi13OUREREREXQrDVSfi5qhGeC83ABy9IiIiIiLqaAxXnUzTA4WT0vJkroSIiIiIqGthuOpkJoY23He1/1wRqurqZa6GiIiIiKjrYLjqZPp6O8G/mz3q6g04cLZI7nKIiIiIiLoMhqtORhAE4+hVUgbvuyIiIiIi6igMV52QcUr2tHyIoihzNUREREREXQPDVSd0ex8P2KuUyC2rwekrZXKXQ0RERETUJTBcdUJalRKj+3oCaBi9IiIiIiKi9sdw1Uk1XRqYyOddERERERF1CIarTmp8/4Zw9fNvJSisqJW5GiIiIiKizo/hqpPyddVioL8LRBFIziiQuxwiIiIiok6P4aoTmxDiAwBISs+TuRIiIiIios6P4aoTa7rvak9mIerqDTJXQ0RERETUuTFcdWKD/V3h6aRGRW09jpwvlrscIiIiIqJOjeGqE1MoBOPEFkmcNZCIiIiIqF0xXHVyE0MZroiIiIiIOgLDVSc3uq8XVEoB2YWVyCqokLscIiIiIqJOi+Gqk3PS2CGytwcAjl4REREREbUnhqsuoGnWQIYrIiIiIqL2w3DVBTTdd3U4uxhlNTqZqyEiIiIi6pwYrrqAXh6OCPJyRL1BxN7MQrnLISIiIiLqlBiuuoiJoT4AgMT0PJkrISIiIiLqnBiuuoim510lZxRAbxBlroaIiIiIqPNhuOoiRgS6wVlrh+LKOvz8W4nc5RARERERdToMV12ESqlAdD8vAEBSGmcNJCIiIiKyNIarLqRp1sBETslORERERGRxDFddSHQ/bwgCkHalDJdLquUuh4iIiIioU2G46kLcHdUY3tMNAB8oTERERERkabKHq7Vr1yIwMBBarRaRkZE4fPjwDZcvKSnB3Llz4efnB41Gg379+mH79u23tM2uZEJIw6WBuxiuiIiIiIgsStZwtXnzZsTFxSE+Ph6pqakYMmQIYmJikJ9v/ot/XV0dJk+ejPPnz2PLli3IyMjA+vXr4e/v3+ZtdjVN913tO1uI6jq9zNUQEREREXUesoarVatWYfbs2Zg5cybCwsKwbt06ODg4YMOGDWaX37BhA4qLi/Htt99i1KhRCAwMRHR0NIYMGdLmbXY1/X2c4d/NHrX1BqRkFcpdDhERERFRp2En147r6upw7NgxLFy40NimUCgwadIkpKSkmF1n69atiIqKwty5c/Hdd9/By8sLDz74IObPnw+lUtmmbQJAbW0tamtrje/LysoAADqdDjqd7lYP9ZY07d+SdUT388Cmw78h4ddcjAlyt9h2yTq0R5+hzo19hqRinyGp2GdIKmvqM1JqkC1cFRYWQq/Xw8fHx6Tdx8cH6enpZtfJyspCUlISHnroIWzfvh1nz57FM888A51Oh/j4+DZtEwBWrFiBpUuXNmvfuXMnHBwc2nB0lpeQkGCxbTmVCQCU+N/PFxGpPA9BsNimyYpYss9Q18A+Q1Kxz5BU7DMklTX0maqqqlYvKylclZSU4JtvvsHevXtx4cIFVFVVwcvLC8OGDUNMTAxGjhwpuVgpDAYDvL298f7770OpVCI8PByXLl3CW2+9hfj4+DZvd+HChYiLizO+LysrQ0BAAKZMmQIXFxdLlN5mOp0OCQkJmDx5MlQqlUW2OUGnxycrdqGkzoCg8DEI8XW2yHbJOrRHn6HOjX2GpGKfIanYZ0gqa+ozTVe1tUarwtXly5exePFifPbZZ+jevTsiIiIwdOhQ2Nvbo7i4GLt27cLKlSvRq1cvxMfHY/r06TfdpqenJ5RKJfLy8kza8/Ly4Ovra3YdPz8/qFQqKJVKY1toaChyc3NRV1fXpm0CgEajgUajadauUqlk/2U2sWQtKpUKo4M98VNaPvacLcagAF4a2BlZU/8l28A+Q1Kxz5BU7DMklTX0GSn7b1W4GjZsGGbMmIFjx44hLCzM7DLV1dX49ttvsWbNGly8eBEvvvjiDbepVqsRHh6OxMRETJs2DUDDyFRiYiJiY2PNrjNq1Chs2rQJBoMBCkXDXByZmZnw8/ODWq0GAMnb7KomhPjgp7R8JKblYe74YLnLISIiIiKyea0KV6dPn4aHh8cNl7G3t8cDDzyABx54AEVFRa3aeVxcHGbMmIERI0YgIiICa9asQWVlJWbOnAkAePTRR+Hv748VK1YAAObMmYN//etfeO655/DXv/4VZ86cwfLly/Hss8+2epvUYHyIFwDg+MUSFFXUwsOp+cgdERERERG1XqvC1c2CVVuXnz59OgoKCrB48WLk5uZi6NCh2LFjh3FCipycHOMIFQAEBATgxx9/xAsvvIDBgwfD398fzz33HObPn9/qbVIDP1d7hPm54PSVMuzOLMB9w3vIXRIRERERkU1rVbjaunVrqzc4depUSQXExsa2eMlecnJys7aoqCgcPHiwzduk300M9cbpK2VITM9nuCIiIiIiukWtCldN9y81EQQBoiiavG+i1+stUxm1uwkh3ngn6Sz2ZBRApzdApZT1mdJERERERDatVd+mDQaD8bVz504MHToU//vf/1BSUoKSkhJs374dw4cPx44dO9q7XrKgIT26wcNRjfLaehw5Xyx3OURERERENk3yQ4Sff/55rFu3DqNHjza2xcTEwMHBAU8++STS0tIsWiC1H4VCwLj+3vgq9TckpeVjZJCn3CUREREREdksydeBnTt3Dt26dWvW7urqivPnz1ugJOpIE0O9AQBJGfkyV0JEREREZNskh6vbbrsNcXFxJg/qzcvLw7x58xAREWHR4qj9jenrCTuFgKyCSmQXVspdDhERERGRzZIcrjZs2IArV66gZ8+eCA4ORnBwMHr27IlLly7hww8/bI8aqR05a1WI7OMOAEhK5+gVEREREVFbSb7nKjg4GL/88gsSEhKQnp4OAAgNDcWkSZNMZg0k2zG+vzf2ny1CUnoenhjdW+5yiIiIiIhskuRwBTRMvT5lyhSMHTsWGo2GocrGTQz1wavb0nA4uxjlNTo4a1Vyl0REREREZHMkXxZoMBjwyiuvwN/fH05OTsjOzgYA/P3vf+dlgTaqt6cj+ng6QqcXse9ModzlEBERERHZJMnh6tVXX8XGjRvx5ptvQq1WG9sHDhyIDz74wKLFUceZENIwa2Ai77siIiIiImoTyeHqk08+wfvvv4+HHnoISqXS2D5kyBDjPVhkeyY0Tsm+Kz0fBoMoczVERERERLZHcri6dOkSgoODm7UbDAbodDqLFEUd77ZAdzhr7FBUWYeffyuRuxwiIiIiIpsjOVyFhYVh7969zdq3bNmCYcOGWaQo6ngqpQJj+3kBaBi9IiIiIiIiaSTPFrh48WLMmDEDly5dgsFgwNdff42MjAx88skn+OGHH9qjRuogE0K8se3kFSSm5yNuSn+5yyEiIiIisimSR67++Mc/4vvvv8dPP/0ER0dHLF68GGlpafj+++8xefLk9qiROsi4/l4QBODXy2XILa2RuxwiIiIiIpvSpudcjRkzBgkJCZauhWTm4aTB0IBuOJ5TgqT0fDwY2VPukoiIiIiIbIbkkas+ffqgqKioWXtJSQn69OljkaJIPhMbp2RPSs+TuRIiIiIiItsiOVydP38eer2+WXttbS0uXbpkkaJIPhNCfAAA+88WoUbX/PdMRERERETmtfqywK1btxp//vHHH+Hq6mp8r9frkZiYiMDAQIsWRx0v1M8Zfq5aXCmtQUpWEcb395a7JCIiIiIim9DqcDVt2jQAgCAImDFjhslnKpUKgYGBePvtty1aHHU8QRAwIcQbnx3KQVJaPsMVEREREVErtfqyQIPBAIPBgJ49eyI/P9/43mAwoLa2FhkZGfjDH/7QnrVSB5lgvO8qH6IoylwNEREREZFtkHzPVXZ2Njw9PdujFrISI4M8obFT4FJJNTLzKuQuh4iIiIjIJrRpKvbExEQkJiYaR7CutWHDBosURvKxVysxKtgTSen5SEzPQ39fZ7lLIiIiIiKyepJHrpYuXYopU6YgMTERhYWFuHr1qsmLOgfjpYFp+TJXQkRERERkGySPXK1btw4bN27EI4880h71kJVoClepOVdRXFkHd0e1zBUREREREVk3ySNXdXV1GDlyZHvUQlakezd7hPg6wyACuzM5ekVEREREdDOSw9WsWbOwadOm9qiFrMzE0KZZAwtkroSIiIiIyPq16rLAuLg4488GgwHvv/8+fvrpJwwePBgqlcpk2VWrVlm2QpLNhBAfrN11Drsz8qHTG6BSSs7iRERERERdRqvC1fHjx03eDx06FABw6tQpk3ZBECxTFVmFoQHd4O6oRnFlHY5duIrb+3jIXRIRERERkdVqVbjatWtXe9dBVkipEDCunxe+Pn4JSen5DFdERERERDfA67zohiY03neVmJYncyVERERERNZN8lTs9957r9nL/wRBgFarRXBwMB588EH079/fIgWSvMb09YKdQsC5gkpcKKpELw9HuUsiIiIiIrJKkkeuXF1dkZSUhNTUVAiCAEEQcPz4cSQlJaG+vh6bN2/GkCFDsH///vaolzqYq70KtwW6AwCS0jklOxERERFRSySHK19fXzz44IPIysrCV199ha+++grnzp3Dww8/jKCgIKSlpWHGjBmYP39+e9RLMvh9SnaGKyIiIiKilkgOVx9++CGef/55KBS/r6pQKPDXv/4V77//PgRBQGxsbLOZBMl2jQ9pCFcHs4pQUVsvczVERERERNZJcriqr69Henp6s/b09HTo9XoAgFar5bTsnUgfT0cEejhApxex70yh3OUQEREREVklyeHqkUcewRNPPIHVq1dj37592LdvH1avXo0nnngCjz76KABg9+7dGDBggMWLJXkIgoAJIT4AgKR0zhpIRERERGSO5HC1evVqPP/883jzzTcxduxYjB07Fm+++SZeeOEFrFq1CgAwZcoUfP75563a3tq1axEYGAitVovIyEgcPny4xWU3btxonESj6aXVak2WqaioQGxsLHr06AF7e3uEhYVh3bp1Ug+TrvP7fVcFMBhEmashIiIiIrI+kqdiVyqVWLRoERYtWoSysjIAgIuLi8kyPXv2bNW2Nm/ejLi4OKxbtw6RkZFYs2YNYmJikJGRAW9vb7PruLi4ICMjw/j++ssP4+LikJSUhE8//RSBgYHYuXMnnnnmGXTv3h1Tp06Vcqh0jdsC3eGksUNhRS1OXirFkIBucpdERERERGRVJIera10fqqRatWoVZs+ejZkzZwIA1q1bh23btmHDhg1YsGCB2XUEQYCvr2+L2zxw4ABmzJiBcePGAQCefPJJvPfeezh8+HCL4aq2tha1tbXG902hUafTQafTteXQLKZp/3LXIQAYFeSOH0/nI+HXKwjz5fOurJW19BmyHewzJBX7DEnFPkNSWVOfkVJDq8LV8OHDkZiYCDc3NwwbNuyGk1Wkpqa2asd1dXU4duwYFi5caGxTKBSYNGkSUlJSWlyvoqICvXr1gsFgwPDhw7F8+XKT+7tGjhyJrVu34vHHH0f37t2RnJyMzMxMrF69usVtrlixAkuXLm3WvnPnTjg4OLTqeNpbQkKC3CXAo1YAoMR3R86hb22m3OXQTVhDnyHbwj5DUrHPkFTsMySVNfSZqqqqVi/bqnD1xz/+ERqNBgAwbdq0NhV1vcLCQuj1evj4+Ji0+/j4mJ2NEAD69++PDRs2YPDgwSgtLcXKlSsxcuRI/Prrr+jRowcA4J133sGTTz6JHj16wM7ODgqFAuvXr8fYsWNbrGXhwoWIi4szvi8rK0NAQACmTJlyy6Nzt0qn0yEhIQGTJ0+GSqWStZaIilr8983duFgpIHz0BPi4aG++EnU4a+ozZBvYZ0gq9hmSin2GpLKmPtN0VVtrtCpcxcfHm/25o0VFRSEqKsr4fuTIkQgNDcV7772HV155BUBDuDp48CC2bt2KXr16Yc+ePZg7dy66d++OSZMmmd2uRqMxhsdrqVQq2X+ZTayhFj83FYb06IYTF0uw79xV/CWidffWkTysoc+QbWGfIanYZ0gq9hmSyhr6jJT9S54tEABKSkrwwQcfYOHChSguLgbQcDngpUuXWr0NT09PKJVK5OWZTu2dl5d3w3uqrqVSqTBs2DCcPXsWAFBdXY2XX34Zq1atwj333IPBgwcjNjYW06dPx8qVK1tdG7VsYuMDhRPT82WuhIiIiIjIukgOV7/88gv69euHN954AytXrkRJSQkA4Ouvvza5f+pm1Go1wsPDkZiYaGwzGAxITEw0GZ26Eb1ej5MnT8LPzw/A7xNQKBSmh6VUKmEwGFpdG7VsfGO42nemEDU6vczVEBERERFZD8nhKi4uDo899hjOnDlj8oypu+66C3v27JG8rfXr1+Pjjz9GWloa5syZg8rKSuPsgY8++qhJYFu2bBl27tyJrKwspKam4uGHH8aFCxcwa9YsAA2zF0ZHR2PevHlITk5GdnY2Nm7ciE8++QT33nuv1EMlMwZ0d4GPiwbVOj0OZRfLXQ4RERERkdWQPBX7kSNH8N577zVr9/f3R25urqRtTZ8+HQUFBVi8eDFyc3MxdOhQ7NixwzjJRU5Ojsko1NWrVzF79mzk5ubCzc0N4eHhOHDgAMLCwozLfP7551i4cCEeeughFBcXo1evXnjttdfw9NNPSz1UMkMQBEwI8cF/D+cgKS0P0f285C6JiIiIiMgqSA5XGo3G7IwZmZmZ8PKS/kU7NjYWsbGxZj9LTk42eb969eobTqkOAL6+vvjoo48k10GtNzHEG/89nIPE9HwsmSrecGp+IiIiIqKuQvJlgVOnTsWyZcuMD9MSBAE5OTmYP38+/t//+38WL5Csz8hgD6jtFPjtajXO5FfIXQ4RERERkVWQHK7efvttVFRUwNvbG9XV1YiOjkZwcDCcnZ3x2muvtUeNZGUc1HYYGeQBAEhM46yBRERERERAGy4LdHV1RUJCAvbt24dffvkFFRUVGD58eIvPkKLOaWKIN5IzCrArPR9zxgXJXQ4RERERkewkh6uamhpotVqMHj0ao0ePbo+ayAaMD/EGvvsVRy8Uo6SqDt0c1HKXREREREQkK8mXBXbr1g1jx47F3//+dyQlJaG6uro96iIr18PNASG+zjCIwO7MArnLISIiIiKSneRw9dNPP+GOO+7AoUOHMHXqVLi5uWH06NFYtGgREhIS2qNGslJNDxTmfVdERERERG0IV6NHj8bLL7+MnTt3oqSkBLt27UJwcDDefPNN3HHHHe1RI1mpiY3handmAer1BpmrISIiIiKSl+R7roCGZ1olJycbX7W1tfjDH/6AcePGWbg8smbDerqhm4MKJVU6pOaUIKK3u9wlERERERHJRnK48vf3R3V1NcaNG4dx48Zh/vz5GDx4MB8k2wUpFQLG9/fGN8cvITE9j+GKiIiIiLo0yZcFenl5oaqqCrm5ucjNzUVeXh4ntejCJjReGpjE+66IiIiIqIuTHK5OnDiB3NxcLFiwALW1tXj55Zfh6emJkSNHYtGiRe1RI1mxsf28oFQIOJNfgYvFVXKXQ0REREQkG8nhCmiYjn3q1Kl4+eWXsXDhQvzpT3/CkSNH8Prrr1u6PrJyrvYqjOjlBgBISufoFRERERF1XZLD1ddff41nn30WgwcPho+PD+bMmYOKigq8/fbbSE1NbY8aycpNDG2ckp3hioiIiIi6MMkTWjz99NMYO3YsnnzySURHR2PQoEHtURfZkAkhPli+PR0HzxWhsrYejpo2TUJJRERERGTTJH8Lzs/n6ASZCvJyRE93B+QUV2Hf2ULEDPCVuyQiIiIiog7XqssCKysrJW1U6vJk2wRB4KyBRERERNTltSpcBQcH4/XXX8eVK1daXEYURSQkJODOO+/EP//5T4sVSLah6b6rXRn5MBhEmashIiIiIup4rbosMDk5GS+//DKWLFmCIUOGYMSIEejevTu0Wi2uXr2K06dPIyUlBXZ2dli4cCGeeuqp9q6brExEb3c4qpXIL6/Fr5fLMKiHq9wlERERERF1qFaFq/79++Orr75CTk4OvvzyS+zduxcHDhxAdXU1PD09MWzYMKxfvx533nknlEple9dMVkhjp8SYvl7Y8WsuEtPzGK6IiIiIqMuRNKFFz5498be//Q1/+9vf2qsesmETQryx49dcJKXn4/lJ/eQuh4iIiIioQ7XpIcJE5owL8QIA/PJbKfLLa2SuhoiIiIioYzFckcV4O2sxpPFywOT0ApmrISIiIiLqWAxXZFETQnwAAInpeTJXQkRERETUsRiuyKKapmTfe6YQtfV6mashIiIiIuo4DFdkUQO6u8DbWYOqOj0OZRXLXQ4RERERUYdpU7jau3cvHn74YURFReHSpUsAgP/85z/Yt2+fRYsj2yMIAiaENIxeJaXny1wNEREREVHHkRyuvvrqK8TExMDe3h7Hjx9HbW0tAKC0tBTLly+3eIFke5rCVWJ6HkRRlLkaIiIiIqKOITlcvfrqq1i3bh3Wr18PlUplbB81ahRSU1MtWhzZplHBnlDbKXCxuBrnCirkLoeIiIiIqENIDlcZGRkYO3Zss3ZXV1eUlJRYoiaycY4aO9zexwMAkJjGSwOJiIiIqGuQHK58fX1x9uzZZu379u1Dnz59LFIU2b6JxksDGa6IiIiIqGuQHK5mz56N5557DocOHYIgCLh8+TI+++wzvPjii5gzZ0571Eg2qOm+q2MXrqK0SidzNURERERE7c9O6goLFiyAwWDAxIkTUVVVhbFjx0Kj0eDFF1/EX//61/aokWxQgLsD+vk4ITOvArvPFGDqkO5yl0RERERE1K4kjVzp9Xrs3bsXc+fORXFxMU6dOoWDBw+ioKAAr7zySnvVSDZqQogPACApLU/mSoiIiIiI2p+kcKVUKjFlyhRcvXoVarUaYWFhiIiIgJOTU3vVRzas6dLA5MwC6A2ckp2IiIiIOjfJ91wNHDgQWVlZ7VELdTLDe3aDq70KJVU6HM+5Knc5RERERETtqk3PuXrxxRfxww8/4MqVKygrKzN5ETWxUyowrr8XAM4aSERERESdn+Rwddddd+Hnn3/G1KlT0aNHD7i5ucHNzQ3dunWDm5ub5ALWrl2LwMBAaLVaREZG4vDhwy0uu3HjRgiCYPLSarXNlktLS8PUqVPh6uoKR0dH3HbbbcjJyZFcG926pksDk/i8KyIiIiLq5CTPFrhr1y6L7Xzz5s2Ii4vDunXrEBkZiTVr1iAmJgYZGRnw9vY2u46LiwsyMjKM7wVBMPn83LlzGD16NJ544gksXboULi4u+PXXX82GMGp/0f28oFQIyMgrx8XiKgS4O8hdEhERERFRu5AcrqKjoy2281WrVmH27NmYOXMmAGDdunXYtm0bNmzYgAULFphdRxAE+Pr6trjNRYsW4a677sKbb75pbAsKCrJYzSRNNwc1wnu64fD5YuzKyMejUYFyl0RERERE1C4khysAKCkpwYcffoi0tDQAwIABA/D444/D1dW11duoq6vDsWPHsHDhQmObQqHApEmTkJKS0uJ6FRUV6NWrFwwGA4YPH47ly5djwIABAACDwYBt27bhpZdeQkxMDI4fP47evXtj4cKFmDZtWovbrK2tRW1trfF9071jOp0OOp28D8Bt2r/cddyK6H4eOHy+GImn8/DACH+5y+n0OkOfoY7FPkNSsc+QVOwzJJU19RkpNQiiKEqaI/vo0aOIiYmBvb09IiIiAABHjhxBdXU1du7cieHDh7dqO5cvX4a/vz8OHDiAqKgoY/tLL72E3bt349ChQ83WSUlJwZkzZzB48GCUlpZi5cqV2LNnD3799Vf06NEDubm58PPzg4ODA1599VWMHz8eO3bswMsvv4xdu3a1OOq2ZMkSLF26tFn7pk2b4ODAy9huVW4VsOJnO9gJIpbfpodGKXdFREREREStU1VVhQcffBClpaVwcXG54bKSw9WYMWMQHByM9evXw86uYeCrvr4es2bNQlZWFvbs2dOq7bQlXF1Pp9MhNDQUDzzwAF555RXjNh944AFs2rTJuNzUqVPh6OiI//73v2a3Y27kKiAgAIWFhTc9ge1Np9MhISEBkydPhkqlkrWWthJFERNW78NvV6ux7sGhmBhq/n46sozO0GeoY7HPkFTsMyQV+wxJZU19pqysDJ6enq0KV5IvCzx69KhJsAIAOzs7vPTSSxgxYkSrt+Pp6QmlUom8vDyT9ry8vBveU3UtlUqFYcOG4ezZs8Zt2tnZISwszGS50NBQ7Nu3r8XtaDQaaDQas9uX+5fZxJpqaYuJId74OOUCdp8twh2DeWlgR7D1PkMdj32GpGKfIanYZ0gqa+gzUvYveSp2FxcXs9OaX7x4Ec7Ozq3ejlqtRnh4OBITE41tBoMBiYmJJiNZN6LX63Hy5En4+fkZt3nbbbeZzCYIAJmZmejVq1erayPLmxDqAwBISs+HxMFSIiIiIiKbIHnkavr06XjiiSewcuVKjBw5EgCwf/9+zJs3Dw888ICkbcXFxWHGjBkYMWIEIiIisGbNGlRWVhpnD3z00Ufh7++PFStWAACWLVuG22+/HcHBwSgpKcFbb72FCxcuYNasWcZtzps3D9OnT8fYsWON91x9//33SE5OlnqoZEGRvd3hoFYir6wWv14uw0D/1k9+QkRERERkCySHq5UrV0IQBDz66KOor68H0DBUNmfOHLz++uuStjV9+nQUFBRg8eLFyM3NxdChQ7Fjxw74+DSMcuTk5ECh+H1w7erVq5g9ezZyc3Ph5uaG8PBwHDhwwOQywHvvvRfr1q3DihUr8Oyzz6J///746quvMHr0aKmHShakVSkxOtgTO0/nISk9n+GKiIiIiDodyeFKrVbjH//4B1asWIFz584BaHiOVFtn1YuNjUVsbKzZz64fbVq9ejVWr159020+/vjjePzxx9tUD7WfiaHe2Hk6D4np+Xh2Yl+5yyEiIiIisijJ4aq0tBR6vR7u7u4YNGiQsb24uBh2dnayz65H1mt8/4ZZAn++WIKC8lp4OTefRISIiIiIyFZJntDiL3/5Cz7//PNm7V988QX+8pe/WKQo6py8XbQY1Hg5YHJGvszVEBERERFZluRwdejQIYwfP75Z+7hx41r1bCrq2iaENIxeJaUzXBERERFR5yI5XNXW1honsriWTqdDdXW1RYqizqvpAcJ7MgtQV2+QuRoiIiIiIsuRHK4iIiLw/vvvN2tft24dwsPDLVIUdV4Du7vCy1mDyjo9DmcXy10OEREREZHFSJ7Q4tVXX8WkSZPw888/Y+LEiQCAxMREHDlyBDt37rR4gdS5KBQCxvf3whdHf0Nieh5G9/WUuyQiIiIiIouQPHI1atQopKSkICAgAF988QW+//57BAcH45dffsGYMWPao0bqZCaENDzHLCk9H6IoylwNEREREZFlSB65AoChQ4fis88+s3Qt1EWM7usJtVKBC0VVyCqsRJCXk9wlERERERHdMskjV6mpqTh58qTx/XfffYdp06bh5ZdfRl1dnUWLo87JSWOHyD7uAICkNM4aSERERESdg+Rw9dRTTyEzMxMAkJWVhenTp8PBwQFffvklXnrpJYsXSJ1T05Tsiel5MldCRERERGQZksNVZmYmhg4dCgD48ssvER0djU2bNmHjxo346quvLF0fdVJN4erI+asordbJXA0RERER0a2THK5EUYTB0PB8op9++gl33XUXACAgIACFhYWWrY46rV4ejgj2doLeIGLvmQK5yyEiIiIiumWSw9WIESPw6quv4j//+Q92796Nu+++GwCQnZ0NHx8fixdIndfExtEr3ndFRERERJ2B5HC1Zs0apKamIjY2FosWLUJwcDAAYMuWLRg5cqTFC6TOq+nSwF0Z+dAbOCU7EREREdk2yVOxDx482GS2wCZvvfUWlEqlRYqiriG8lxtctHa4WqXDiYtXEd7LXe6SiIiIiIjaTPLIVUu0Wi1UKpWlNkddgJ1Sgej+jbMG8tJAIiIiIrJxFgtXRG1hvO8qneGKiIiIiGwbwxXJKrqfFxQCkJ5bjksl1XKXQ0RERETUZgxXJCs3RzXCe7kB4OgVEREREdk2hiuS3XjjlOx5MldCRERERNR2FgtXFy9exOOPP26pzVEXMjGk4floB84VobpOL3M1RERERERtY7FwVVxcjI8//thSm6MupJ+PE/y72aO23oAD5wrlLoeIiIiIqE1a/ZyrrVu33vDzrKysWy6GuiZBEDAx1BufpFxAYno+Job6yF0SEREREZFkrQ5X06ZNgyAIEEWxxWUEQbBIUdT1jA9pCFdJafkQp4nsS0RERERkc1p9WaCfnx++/vprGAwGs6/U1NT2rJM6uag+HrBXKZFbVoPTV8rkLoeIiIiISLJWh6vw8HAcO3asxc9vNqpFdCNalRKjgj0BALs4JTsRERER2aBWh6t58+Zh5MiRLX4eHByMXbt2WaQo6pomhjZMyZ7IcEVERERENqjV91yNGTPmhp87OjoiOjr6lguirmt8/4ZwdeJiCQorauHppJG5IiIiIiKi1mv1yFVWVhYv+6N25euqxYDuLhBFIDmjQO5yiIiIiIgkaXW46tu3LwoKfv/CO336dOTl5bVLUdR1TQxpGL1KSmffIiIiIiLb0upwdf2o1fbt21FZWWnxgqhrm9D4jKu9mYWoqzfIXA0RERERUeu1OlwRdYTB/q7wdFKjvLYeR88Xy10OEREREVGrtTpcCYLQ7MGufNArWZpCIRgntuCsgURERERkS1o9W6Aoinjssceg0TTM4FZTU4Onn34ajo6OJst9/fXXlq2QupwJId748thvSErPx9//ECZ3OURERERErdLqcDVjxgyT9w8//LDFiyECgNF9PaFSCsgurERWQQX6eDnJXRIRERER0U21Olx99NFH7VkHkZGzVoXI3h7Yd7YQSen5DFdEREREZBOsYkKLtWvXIjAwEFqtFpGRkTh8+HCLy27cuNF4/1fTS6vVtrj8008/DUEQsGbNmnaonNrLBOOU7LzvioiIiIhsg+zhavPmzYiLi0N8fDxSU1MxZMgQxMTEID+/5S/VLi4uuHLlivF14cIFs8t98803OHjwILp3795e5VM7aQpXh7OLUVajk7kaIiIiIqKbkz1crVq1CrNnz8bMmTMRFhaGdevWwcHBARs2bGhxHUEQ4Ovra3z5+Pg0W+bSpUv461//is8++wwqlao9D4HaQaCnI/p4OaLeIGJvZqHc5RARERER3VSr77lqD3V1dTh27BgWLlxobFMoFJg0aRJSUlJaXK+iogK9evWCwWDA8OHDsXz5cgwYMMD4ucFgwCOPPIJ58+aZtLektrYWtbW1xvdlZWUAAJ1OB51O3lGTpv3LXYccxvfzRFZBJX5Ky8WUUE+5y7EZXbnPUNuwz5BU7DMkFfsMSWVNfUZKDbKGq8LCQuj1+mYjTz4+PkhPTze7Tv/+/bFhwwYMHjwYpaWlWLlyJUaOHIlff/0VPXr0AAC88cYbsLOzw7PPPtuqOlasWIGlS5c2a9+5cyccHBwkHlX7SEhIkLuEDmdfKgBQIuHkJfygyYGCj1WTpCv2Gbo17DMkFfsMScU+Q1JZQ5+pqqpq9bKyhqu2iIqKQlRUlPH9yJEjERoaivfeew+vvPIKjh07hn/84x9ITU1t9UOOFy5ciLi4OOP7srIyBAQEYMqUKXBxcbH4MUih0+mQkJCAyZMnd7nLG3V6Az5+PRnlNfXwHzwSwwK6yV2STejKfYbahn2GpGKfIanYZ0gqa+ozTVe1tYas4crT0xNKpRJ5eXkm7Xl5efD19W3VNlQqFYYNG4azZ88CAPbu3Yv8/Hz07NnTuIxer8ff/vY3rFmzBufPn2+2DY1GY3w48vXblvuX2cSaaukoKhUwtp8Xtv1yBXvOFCOij5fcJdmUrthn6Nawz5BU7DMkFfsMSWUNfUbK/mWd0EKtViM8PByJiYnGNoPBgMTERJPRqRvR6/U4efIk/Pz8AACPPPIIfvnlF5w4ccL46t69O+bNm4cff/yxXY6D2s/ExlkDEzklOxERERFZOdkvC4yLi8OMGTMwYsQIREREYM2aNaisrMTMmTMBAI8++ij8/f2xYsUKAMCyZctw++23Izg4GCUlJXjrrbdw4cIFzJo1CwDg4eEBDw8Pk32oVCr4+vqif//+HXtwdMvG9feGIABpV8pwpbQafq72cpdERERERGSW7OFq+vTpKCgowOLFi5Gbm4uhQ4dix44dxkkucnJyoFD8PsB29epVzJ49G7m5uXBzc0N4eDgOHDiAsLAwuQ6B2pG7oxrDe7rh2IWrSErPx0ORveQuiYiIiIjILNnDFQDExsYiNjbW7GfJyckm71evXo3Vq1dL2r65+6zIdkwI8W4IV2kMV0RERERkvWR/iDDRzUxovO9q/7lC1Oj0MldDRERERGQewxVZvRBfZ3R31aJGZ0DKuSK5yyEiIiIiMovhiqyeIAiYENo0a2DeTZYmIiIiIpIHwxXZhIkhDROcJKXlQxRFmashIiIiImqO4YpsQlSQB7QqBS6X1iA9t1zucoiIiIiImmG4IpugVSkxKsgTAJDEBwoTERERkRViuCKb0XTfFcMVEREREVkjhiuyGU1TsqfmXEVxZZ3M1RARERERmWK4Ipvh52qPMD8XiCKQnMHRKyIiIiKyLgxXZFOaRq8SeWkgEREREVkZhiuyKU33Xe3JKIBOb5C5GiIiIiKi3zFckU0Z0qMbPBzVKK+tx9HzV+Uuh4iIiIjIiOGKbIpSIWBc/4bRq08Pnsd3Jy4h5VwR9AY+WJiIiIiI5GUndwFEUrk7qgAA207mYtvJXACAn6sW8feE4Y6BfnKWRkRERERdGEeuyKbsOHUFH+zNbtaeW1qDOZ+mYsepKzJURURERETEcEU2RG8QsfT70zB3AWBT29LvT/MSQSIiIiKSBcMV2YzD2cW4UlrT4ucigCulNTicXdxxRRERERERNWK4IpuRX95ysLrW0u9/xYZ92cgqqIAochSLiIiIiDoGJ7Qgm+HtrG3Vcum55Vj2w2ks+wHo6e6Acf29EN3PC1FBHnBQs8sTERERUfvgN02yGRG93eHnqkVuaY3Z+64EAJ5OGswa0xt7zhTgSPZV5BRX4ZOUC/gk5QLUdgpE9nZHdD8vjOvvjSAvRwiC0NGHQURERESdFMMV2QylQkD8PWGY82kqBMAkYDVFpFemDcAdA/3wVHQQKmvrceBcEZIz8pGcUYBLJdXYe6YQe88U4tVtaejhZo9x/b0wrp83RgZzVIuIiIiIbg2/TZJNuWOgH959eDiWfn/aZHILXzPPuXLU2GFymA8mh/lAFEWcK6hEckY+dmcW4FBWMX67Wo1PD+bg04M5UCsViOjt3hC2+nshyMuJo1pEREREJAnDFdmcOwb6YXKYLw5nFyO/vAbezlpE9HaHUtFyGBIEAcHeTgj2dsKsMX1QVVePlHNFSM4oQHJmPi4WV2Pf2ULsO9swquXfrXFUq783RgZ5wFHD/1SIiIiI6Mb4jZFsklIhICrIo83rO6jtMDHUBxNDG0a1sgorG4JWRj4OZRfjUkk1PjuUg88ONYxq3dbbDeP6eWNcfy8Ee3NUi4iIiIiaY7iiLk8QBAR5OSHIywlPjO6Nqrp6HMxqHNXKKEBOcRX2ny3C/rNFeG17w6hWdH8vjOvnhVHBnhzVIiIiIiIADFdEzTio7TAhxAcTQhpGtbKbRrUyC3AwqwiXSqqx6VAONh3KgUop4LZAd+MlhH05qkVERETUZTFcEd2AIAjo4+WEPl5OeHx0b1TX6RtHtfKRnFmAC0VVOHCuCAfOFWH59nR0d9Uiun/D5YOjgj3hxFEtIiIioi6D3/yIJLBXKzE+xBvjQ7wBoHFUq2Gq94NZRbhcWoP/Hs7Bfw83jGqN6NUwqhXd3wv9fZw5qkVERETUiTFcEd2C3p6O6O3ZGzNH9UaNTo+UrCLsbpwY43xRFVKyipCSVYQV/0uHn6u28QHGDaNazlqV3OUTERERkQUxXBFZiFalxPj+3hjf3xvAAJxvGtXKLEDKuSJcKa3B50cu4vMjF2GnEBDeyw3jGi8hDPHlqBYRERGRrWO4ImongZ6OeMyzNx5rHNVqmoFwd2YBsgsrcSi7GIeyi/HGjnT4ulwzqtXXEy4c1SIiIiKyOQxXRB1Aq1I2jlI13Kt1oej352qlZBUht6wGm49exOajDaNaw3u5NcxA2M8boX4c1SIiIiKyBQxXRDLo5eGIGSMdMWNkIGp0ehzKLkZyRj52ZxQgq7ASh7OLcTi7GG/uyICPi6ZxVMsbo28yqqU3iDiUXYxjhQI8sosRFewNpYLBjIiIiKgjMFwRyUyrUiK6nxei+3kB9wA5RVVIzmyYgfDAuULkldXii6O/4Yujv0GpEBDe063hIcb9vRDm52Ic1dpx6gqWfn8aV0prACjxyZmj8HPVIv6eMNwx0E/egyQiIiLqAhiuiKxMTw8HPBoViEejGka1DmcXNz7EOB9ZBZU4fL4Yh88X460fM+Dt3DCq1c1BhQ/2ZkO8blu5pTWY82kq3n14OAMWERERUTtjuCKyYlqVEmP7eWFsPy8sRhguFlchObMAuzPysf9sEfLLa/Hlsd9aXF8EIABY+v1pTA7z5SWCRERERO2I4YrIhgS4O+CR23vhkdt7obZejyPZV7Hp0AVsP5Xb4joigCulNbjzH3sQ5OUETycNPJ008HLWwNNJDU9nDbwa32tVyo47GCIiIqJOxirC1dq1a/HWW28hNzcXQ4YMwTvvvIOIiAizy27cuBEzZ840adNoNKipqQEA6HQ6/N///R+2b9+OrKwsuLq6YtKkSXj99dfRvXv3dj8Woo6isVNidF9PFFXW3jBcNcnMq0BmXsUNl3HS2P0euowB7LowxiBGREREZJbs4Wrz5s2Ii4vDunXrEBkZiTVr1iAmJgYZGRnw9vY2u46LiwsyMjKM76+dprqqqgqpqan4+9//jiFDhuDq1at47rnnMHXqVBw9erTdj4eoo3k7a1u13HMT+8LdUY3CiloUlNc2/FlRh8LyWhRU1KKu3oCK2npU1NYju7Dypttz1tgZR708nRtDl5MGns7Nw5g1BDG9QcTh7GLkl9fA21mLiN7uvEySiIiILEr2cLVq1SrMnj3bOBq1bt06bNu2DRs2bMCCBQvMriMIAnx9fc1+5urqioSEBJO2f/3rX4iIiEBOTg569uzZbJ3a2lrU1tYa35eVlQFoGAXT6XRtOi5Ladq/3HWQ9RrWwxm+LhrkldU2m9ACaLjnytdVgzljA1sME6IooqK2HgXldSisrEVRRV1D8Kpo+rnhz8LGn3V6EeW19ShvbRDT2sHTUQ0PJ3VDAHNSw8NJAy+nhjZP488aaOwUt3ZCzPjx1zy8uj0duWW//3fu66LB/90VgpgBPhbfn63h3zMkFfsMScU+Q1JZU5+RUoMgiqK572Mdoq6uDg4ODtiyZQumTZtmbJ8xYwZKSkrw3XffNVtn48aNmDVrFvz9/WEwGDB8+HAsX74cAwYMaHE/P/30E6ZMmYKSkhK4uLg0+3zJkiVYunRps/ZNmzbBwcGhbQdH1IF+LhKwIbMplFwboBr+8368nwFDPCzzn7ooAtV6oFwHlNcB5ToB5TqgrPHPch1QVvf7z3pR2uiQvVKEswoNL7UIFxXgrGpsU//+s4sKaE0O68hzQ0RERJ1PVVUVHnzwQZSWlprNEteSNVxdvnwZ/v7+OHDgAKKiooztL730Enbv3o1Dhw41WyclJQVnzpzB4MGDUVpaipUrV2LPnj349ddf0aNHj2bL19TUYNSoUQgJCcFnn31mtg5zI1cBAQEoLCy86QlsbzqdDgkJCZg8eTJUqpYfHktkbnTGz1WDRXfKNzojiiLKaupR2DgKVmgyGnZdW2UddHppfx25aO2Mlx5eOxrW9LO7gwrPbDqBgoo6s+s3jertihvbZS8R1BtEHDxXgKSUY5gQFY7bg7y67Lmg1uP/m0gq9hmSypr6TFlZGTw9PVsVrmS/LFCqqKgokyA2cuRIhIaG4r333sMrr7xisqxOp8P9998PURTx7rvvtrhNjUYDjUbTrF2lUsn+y2xiTbWQdfrD0B64c7A/Us7mY+feQ5gyJhJRwd6yf1H2VKvh6XLzEWBRFFFarWu8J6zh8sPCpnvDGv8srKhDQXktiiobLk0sq6lHWU09sgqr2lRbw0yKtXjqs+Po5eEIrUoJrZ0CGpWy4WeVAvbX/Ky1U0KjUja2KRrbf/9MYWOhpPmDp0/wwdPX4H16N8f/N5FU7DMklTX0GSn7lzVceXp6QqlUIi8vz6Q9Ly+vxXuqrqdSqTBs2DCcPXvWpL0pWF24cAFJSUmyj0ARdQSlQkBkb3cUpYmItLEvgoIgoJuDGt0c1Ag2P5eNUVMQK2icjKMpdBU2BrKGtlpcLK5GafXNr5PenVkIoPCWj0Ftp4DW7rrQZfxZec1nDX/aq5SNQa4hnGlVStirf/9Z07S+nRL2atPlNHaKWwpzO05dwZxPU/ng6RaYBs8GDJ5ERHQzsoYrtVqN8PBwJCYmGu+5MhgMSExMRGxsbKu2odfrcfLkSdx1113GtqZgdebMGezatQseHh7tUT4RyeTaINbXx7nF5VLOFeGB9Qdvur3ptwXA21mDGp0eNTpDw5/1BlTX6VFbr7+uXY/qOgNqG3++9lLGunoD6uoNKKupt8hx3ozaTmE6imbX8HOz0bXGdq264We1nQLv7T5ndgKUprb/+/aUcTRPbaeASilArVRApVRAbaeAnUIwmam1M2HwJCKitpL9ssC4uDjMmDEDI0aMQEREBNasWYPKykrj7IGPPvoo/P39sWLFCgDAsmXLcPvttyM4OBglJSV46623cOHCBcyaNQtAQ7D605/+hNTUVPzwww/Q6/XIzW14BpC7uzvUarU8B0pEHS6itzv8XLXILa25wUyKWiy/d1CbR/nq9QbU1htQrTMNYQ2hrCGg1dRfE850zcOa6Wc3bq83NA9zpdVtOz83UlhRhzv/sfeGyzSELaExfP0evNRKBVR2wu9tje0qpXDd+8aXnQCN8edrtyM03+51+zT989YDoN4gYun3p1sMngKApd+fxuQwX5saGSYioo4he7iaPn06CgoKsHjxYuTm5mLo0KHYsWMHfHwabsDPycmBQvH7lGBXr17F7NmzkZubCzc3N4SHh+PAgQMICwsDAFy6dAlbt24FAAwdOtRkX7t27cK4ceM65LiISH5KhYD4e8Iw59NUCIDJF+amr8Xx94Td0pdkO6UCdkoFHDUd89dpvd5gHFW7NsQ1BbDqawNcfcMI2/UB70xeBQ6fL77pvhzVSgiCgDp9Q4i7Xp3egDo9UFmnb49DtYjWBkBN4+flNTqTSwGv13CfXg0OZxcjKohXRRARkSnZwxUAxMbGtngZYHJyssn71atXY/Xq1S1uKzAwEDJOgEhEVuaOgX549+Hhze6f8bXR+2fslAo4KRVwuoUw19rLJT+YcZsxQIiiiHqDCJ3eAF292BisDNDVG6Br+lkvou7a9/VN7des0/h5wzKiyXtd4yigTi+abPf3ZRr2X3ftdhu30dEBcMn3vyKytzsCPRzR28sRvT0c0cPNHnZKyz+njYiIbIdVhCsiovZ0x0A/TA7z5cxvjVp7uWREb/ff2wTBeFkfrPTqalEUoTeIjcFOvCaAXRvIrgtojWGuTq+Hrl5Eem4ZNuw/f9N9ZeSWIyO33KTNTiGgp7sDAj0dTUJXby9H+LlobW42SSIiko7hioi6BKVC4GVcjTrickk5CIIAO6XQMHrUxgCoN4j436ncFoMnAHg4qvFiTD9cKKpGdmEFzhdW4XxRJWrrDcgqrERWYWWzdTR2CvTycEBvT0cEejaGLs+Gl5ezptNODkJE1NUwXBERdUGd7XJJS2lN8Hzt3oHNzo/BIOJKWQ3OF1Yiu/F1vrAS2UWVyCmqQm29AZl5FcjMq2i2T0e1smG065rQFdgYvNwcVAxeREQ2hOGKiKiLarpc0toePC23tgRPhUKAfzd7+Hezx6hgT5PP6vUGXCqpvi50VSG7sAKXrlajsk6PXy+X4dfLZc2262qvagxdDujt6YRATwf0afzTWcsHsRIRWRuGKyKiLsyWHzzdnix5n56dUoFeHo7o5eGIcf1NP6ut1+NicRWyC6uMI13ZBZU4X1SJK6U1KK3W4eeLJfj5Ykmz7Xo6qRtGuTwaRrr6NI54BXo4wl6tbOORExHRrWC4IiIiMqMj7tPT2CkR7O2MYO/mD8OurtPjfFFls9CVXViFwopaFFbUobCiDkfOX222rp+rtlno6u3pgAB3B2jsbi146Q0iDmUX41ihAI/sYo52EhFdg+GKiIjICtmrlQj1c0Gon0uzz8prdDhfWHVd6Gp4lVY3PKvrSmkNUrKKTNZTCIC/mz16ezqht4eD8d6u3p6O8O9286nkd5y6cs3lkkp8cuYo/Lr4fXpN9AaRM5K2gIHcPPaZltlyn2G4IiIisjHOWhUG9XDFoB6uzT67WllnNnSdL6xEZZ0eF4urcbG4GnuuW0+lFBDg7oDeHo4moSvQs2Eq+Z2nczHn09RmsyjmltZgzqepePfh4V02YJmGzgYMnQ0YyM1jn2mZrfcZhisiIqJOxM1RDTdHNYb3dDNpF0URBRW1xtCV1Ri4TKaSL6hEVkHzqeTVSgEGEWanp29qW/TNKbg7qqFSKmCnUEChAOwUCigVgFKhgJ1CgEIhNPwpCCbvlY0vO4Vgc7Mj7jh1haGzBTw35vG8tKwznBuGKyIioi5AEAR4O2vh7axFZB/Te8munUr+99D1+1TydfqWnvr1u6LKOtz/3kEL1AmTAKY0vhqCmmlwE6AUrl3mmlfjc89utIzddcsrWwiDpss0bFchCFAIwBs7Mm4YOhd+fRIGg9jlHiJtMIh4+dtTPDfX4Xlp2c3OjQBg6fenMTnM16ovEWS4IiIi6uJuNpX8xynn8coPaTfdjqeTGlqVEnqD+PtLFKHXi6hv+rmxvSWiCOj0IgARtbd6YFbgapUOz2w6LncZVonnxjyeF/NEAFdKa3A4u7jdJxu6FQxXRERE1CI7pQJhfs3v7TLnnQeGt+pLjyiKMIgwBq16gwEGA1BvMJgEsIbPRBga/zQJbAYR9XoRBvH6ZQzQN27LIJouozfcZNui+WWatqk3GKAXG/6s14u4XFKNU2aeT3a93p6O8HBUt+ocdhZFlXXILmx+ien1utq54XlpWWvPTX55zU2XkRPDFREREd1QRG93+LlqkVtaY/aSHQEND1mO6O3equ0JggClgGsu7bHN53KlnCvCA+tvfink8nsHWfW/tLcHnhvzeF5a1tpz4+2s7YBq2u7Gc64SERFRl6dUCIi/JwxAQ5C6VtP7+HvCrPo+iPbQFDpbOmoBDTPAtTZ0diY8N+bxvLSss5wbhisiIiK6qTsG+uHdh4fD19X0X419XbU2MYNXe2DobBnPjXk8Ly3rLOeG4YqIiIha5Y6Bftg3fwI+fXwEHu2rx6ePj8C++RO6ZLBqwtDZMp4b83heWtYZzg3vuSIiIqJWUyoERPZ2R1GaiMje7lb/r8gd4Y6Bfpgc5ovD2cXIL6+Bt3PDpUs8N7+fm5Sz+di59xCmjIlEVLB3lz837DMts/U+w3BFREREdIuUCqHLTUDQWgzk5rHPtMyW+wwvCyQiIiIiIrIAhisiIiIiIiILYLgiIiIiIiKyAIYrIiIiIiIiC2C4IiIiIiIisgCGKyIiIiIiIgvgVOxmiKIIACgrK5O5EkCn06GqqgplZWVQqVRyl0M2gH2GpGKfIanYZ0gq9hmSypr6TFMmaMoIN8JwZUZ5eTkAICAgQOZKiIiIiIjIGpSXl8PV1fWGywhiayJYF2MwGHD58mU4OztDEOR9aFlZWRkCAgJw8eJFuLi4yFoL2Qb2GZKKfYakYp8hqdhnSCpr6jOiKKK8vBzdu3eHQnHju6o4cmWGQqFAjx495C7DhIuLi+wdi2wL+wxJxT5DUrHPkFTsMySVtfSZm41YNeGEFkRERERERBbAcEVERERERGQBDFdWTqPRID4+HhqNRu5SyEawz5BU7DMkFfsMScU+Q1LZap/hhBZEREREREQWwJErIiIiIiIiC2C4IiIiIiIisgCGKyIiIiIiIgtguCIiIiIiIrIAhisrsHbtWgQGBkKr1SIyMhKHDx++4fJffvklQkJCoNVqMWjQIGzfvr2DKiVrIaXPrF+/HmPGjIGbmxvc3NwwadKkm/Yx6nyk/j3T5PPPP4cgCJg2bVr7FkhWR2qfKSkpwdy5c+Hn5weNRoN+/frx/09djNQ+s2bNGvTv3x/29vYICAjACy+8gJqamg6qluS0Z88e3HPPPejevTsEQcC3335703WSk5MxfPhwaDQaBAcHY+PGje1eZ1swXMls8+bNiIuLQ3x8PFJTUzFkyBDExMQgPz/f7PIHDhzAAw88gCeeeALHjx/HtGnTMG3aNJw6daqDKye5SO0zycnJeOCBB7Br1y6kpKQgICAAU6ZMwaVLlzq4cpKL1D7T5Pz583jxxRcxZsyYDqqUrIXUPlNXV4fJkyfj/Pnz2LJlCzIyMrB+/Xr4+/t3cOUkF6l9ZtOmTViwYAHi4+ORlpaGDz/8EJs3b8bLL7/cwZWTHCorKzFkyBCsXbu2VctnZ2fj7rvvxvjx43HixAk8//zzmDVrFn788cd2rrQNRJJVRESEOHfuXON7vV4vdu/eXVyxYoXZ5e+//37x7rvvNmmLjIwUn3rqqXatk6yH1D5zvfr6etHZ2Vn8+OOP26tEsjJt6TP19fXiyJEjxQ8++ECcMWOG+Mc//rEDKiVrIbXPvPvuu2KfPn3Eurq6jiqRrIzUPjN37lxxwoQJJm1xcXHiqFGj2rVOsj4AxG+++eaGy7z00kvigAEDTNqmT58uxsTEtGNlbcORKxnV1dXh2LFjmDRpkrFNoVBg0qRJSElJMbtOSkqKyfIAEBMT0+Ly1Lm0pc9cr6qqCjqdDu7u7u1VJlmRtvaZZcuWwdvbG0888URHlElWpC19ZuvWrYiKisLcuXPh4+ODgQMHYvny5dDr9R1VNsmoLX1m5MiROHbsmPHSwaysLGzfvh133XVXh9RMtsWWvv/ayV1AV1ZYWAi9Xg8fHx+Tdh8fH6Snp5tdJzc31+zyubm57VYnWY+29JnrzZ8/H927d2/2lxR1Tm3pM/v27cOHH36IEydOdECFZG3a0meysrKQlJSEhx56CNu3b8fZs2fxzDPPQKfTIT4+viPKJhm1pc88+OCDKCwsxOjRoyGKIurr6/H000/zskAyq6Xvv2VlZaiuroa9vb1MlTXHkSuiLuT111/H559/jm+++QZarVbucsgKlZeX45FHHsH69evh6ekpdzlkIwwGA7y9vfH+++8jPDwc06dPx6JFi7Bu3Tq5SyMrlZycjOXLl+Pf//43UlNT8fXXX2Pbtm145ZVX5C6N6JZw5EpGnp6eUCqVyMvLM2nPy8uDr6+v2XV8fX0lLU+dS1v6TJOVK1fi9ddfx08//YTBgwe3Z5lkRaT2mXPnzuH8+fO45557jG0GgwEAYGdnh4yMDAQFBbVv0SSrtvw94+fnB5VKBaVSaWwLDQ1Fbm4u6urqoFar27Vmkldb+szf//53PPLII5g1axYAYNCgQaisrMSTTz6JRYsWQaHgv//T71r6/uvi4mJVo1YAR65kpVarER4ejsTERGObwWBAYmIioqKizK4TFRVlsjwAJCQktLg8dS5t6TMA8Oabb+KVV17Bjh07MGLEiI4olayE1D4TEhKCkydP4sSJE8bX1KlTjTM0BQQEdGT5JIO2/D0zatQonD171hjEASAzMxN+fn4MVl1AW/pMVVVVswDVFM5FUWy/Yskm2dT3X7ln1OjqPv/8c1Gj0YgbN24UT58+LT755JNit27dxNzcXFEURfGRRx4RFyxYYFx+//79op2dnbhy5UoxLS1NjI+PF1UqlXjy5Em5DoE6mNQ+8/rrr4tqtVrcsmWLeOXKFeOrvLxcrkOgDia1z1yPswV2PVL7TE5Ojujs7CzGxsaKGRkZ4g8//CB6e3uLr776qlyHQB1Map+Jj48XnZ2dxf/+979iVlaWuHPnTjEoKEi8//775ToE6kDl5eXi8ePHxePHj4sAxFWrVonHjx8XL1y4IIqiKC5YsEB85JFHjMtnZWWJDg4O4rx588S0tDRx7dq1olKpFHfs2CHXIbSI4coKvPPOO2LPnj1FtVotRkREiAcPHjR+Fh0dLc6YMcNk+S+++ELs16+fqFarxQEDBojbtm3r4IpJblL6TK9evUQAzV7x8fEdXzjJRurfM9diuOqapPaZAwcOiJGRkaJGoxH79Okjvvbaa2J9fX0HV01yktJndDqduGTJEjEoKEjUarViQECA+Mwzz4hXr17t+MKpw+3atcvsd5OmPjJjxgwxOjq62TpDhw4V1Wq12KdPH/Gjjz7q8LpbQxBFjr0SERERERHdKt5zRUREREREZAEMV0RERERERBbAcEVERERERGQBDFdEREREREQWwHBFRERERERkAQxXREREREREFsBwRUREREREZAEMV0RERERERBbAcEVERDYpOTkZgiCgpKSkQ/e7ceNGdOvW7Za2cf78eQiCgBMnTrS4jFzHR0REbcdwRUREVkcQhBu+lixZIneJREREzdjJXQAREdH1rly5Yvx58+bNWLx4MTIyMoxtTk5OOHr0qOTt1tXVQa1WW6RGIiKi63HkioiIrI6vr6/x5erqCkEQTNqcnJyMyx47dgwjRoyAg4MDRo4caRLClixZgqFDh+KDDz5A7969odVqAQAlJSWYNWsWvLy84OLiggkTJuDnn382rvfzzz9j/PjxcHZ2houLC8LDw5uFuR9//BGhoaFwcnLCHXfcYRIIDQYDli1bhh49ekCj0WDo0KHYsWPHDY95+/bt6NevH+zt7TF+/HicP3/+Vk4hERHJgOGKiIhs2qJFi/D222/j6NGjsLOzw+OPP27y+dmzZ/HVV1/h66+/Nt7j9Oc//xn5+fn43//+h2PHjmH48OGYOHEiiouLAQAPPfQQevTogSNHjuDYsWNYsGABVCqVcZtVVVVYuXIl/vOf/2DPnj3IycnBiy++aPz8H//4B95++22sXLkSv/zyC2JiYjB16lScOXPG7DFcvHgR9913H+655x6cOHECs2bNwoIFCyx8poiIqL3xskAiIrJpr732GqKjowEACxYswN13342amhrjKFVdXR0++eQTeHl5AQD27duHw4cPIz8/HxqNBgCwcuVKfPvtt9iyZQuefPJJ5OTkYN68eQgJCQEA9O3b12SfOp0O69atQ1BQEAAgNjYWy5YtM36+cuVKzJ8/H3/5y18AAG+88QZ27dqFNWvWYO3atc2O4d1330VQUBDefvttAED//v1x8uRJvPHGGxY7T0RE1P44ckVERDZt8ODBxp/9/PwAAPn5+ca2Xr16GYMV0HDJX0VFBTw8PODk5GR8ZWdn49y5cwCAuLg4zJo1C5MmTcLrr79ubG/i4OBgDFZN+23aZ1lZGS5fvoxRo0aZrDNq1CikpaWZPYa0tDRERkaatEVFRbX6HBARkXXgyBUREdm0ay/XEwQBQMM9T00cHR1Nlq+oqICfnx+Sk5ObbatpivUlS5bgwQcfxLZt2/C///0P8fHx+Pzzz3Hvvfc222fTfkVRtMThEBGRDePIFRERdSnDhw9Hbm4u7OzsEBwcbPLy9PQ0LtevXz+88MIL2LlzJ+677z589NFHrdq+i4sLunfvjv3795u079+/H2FhYWbXCQ0NxeHDh03aDh48KPHIiIhIbgxXRETUpUyaNAlRUVGYNm0adu7cifPnz+PAgQNYtGgRjh49iurqasTGxiI5ORkXLlzA/v37ceTIEYSGhrZ6H/PmzcMbb7yBzZs3IyMjAwsWLMCJEyfw3HPPmV3+6aefxpkzZzBv3jxkZGRg06ZN2Lhxo4WOmIiIOgovCyQioi5FEARs374dixYtwsyZM1FQUABfX1+MHTsWPj4+UCqVKCoqwqOPPoq8vDx4enrivvvuw9KlS1u9j2effRalpaX429/+hvz8fISFhWHr1q3NJsZo0rNnT3z11Vd44YUX8M477yAiIgLLly9vNvMhERFZN0HkReJERERERES3jJcFEhERERERWQDDFRERERERkQUwXBEREREREVkAwxUREREREZEFMFwRERERERFZAMMVERERERGRBTBcERERERERWQDDFRERERERkQUwXBEREREREVkAwxUREREREZEFMFwRERERERFZwP8HYF/lwgMT81YAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best threshold = 0.00\n",
            "\n",
            "Confusion matrix\n",
            " [[47668  2200]\n",
            " [21441  5395]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Non‑Joke (0)       0.69      0.96      0.80     49868\n",
            "   Joke (>0)       0.71      0.20      0.31     26836\n",
            "\n",
            "    accuracy                           0.69     76704\n",
            "   macro avg       0.70      0.58      0.56     76704\n",
            "weighted avg       0.70      0.69      0.63     76704\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    precision_recall_fscore_support,\n",
        "    confusion_matrix,\n",
        "    classification_report\n",
        ")\n",
        "\n",
        "\n",
        "def find_best_threshold_from_preds(\n",
        "        preds: np.ndarray,\n",
        "        labels: np.ndarray,\n",
        "        *,\n",
        "        apply_sigmoid: bool = False,\n",
        "        thresh_grid = np.arange(0.0, 1.01, 0.1),\n",
        "        average: str = \"weighted\"\n",
        "    ):\n",
        "    probs = 1 / (1 + np.exp(-preds)) if apply_sigmoid else preds.copy()\n",
        "\n",
        "    best_f1, best_thresh = -1.0, 0.5\n",
        "    history = {\"threshold\": [], \"precision\": [], \"recall\": [], \"f1\": []}\n",
        "\n",
        "    for t in thresh_grid:\n",
        "        bin_pred = (probs > t).astype(int)\n",
        "        p, r, f, _ = precision_recall_fscore_support(\n",
        "            labels, bin_pred, average=average, zero_division=0\n",
        "        )\n",
        "\n",
        "        history[\"threshold\"].append(t)\n",
        "        history[\"precision\"].append(p)\n",
        "        history[\"recall\"].append(r)\n",
        "        history[\"f1\"].append(f)\n",
        "\n",
        "        if f > best_f1:\n",
        "            best_f1, best_thresh = f, t\n",
        "\n",
        "        print(f\"thr {t:4.2f} | P={p:5.3f}  R={r:5.3f}  F1({average})={f:5.3f}\")\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(history[\"threshold\"], history[\"f1\"], marker=\"o\")\n",
        "    plt.xlabel(\"Threshold\")\n",
        "    plt.ylabel(f\"F1 score ({average})\")\n",
        "    plt.title(f\"F1 ({average}) vs threshold\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return best_thresh, history\n",
        "\n",
        "binary_true = (labels > 0).astype(int)\n",
        "\n",
        "best_thr, _ = find_best_threshold_from_preds(\n",
        "    preds, binary_true,\n",
        "    apply_sigmoid=False,\n",
        "    average=\"weighted\"\n",
        ")\n",
        "print(f\"\\nBest threshold = {best_thr:.2f}\")\n",
        "\n",
        "binary_pred_best = (preds > best_thr).astype(int)\n",
        "\n",
        "cm = confusion_matrix(binary_true, binary_pred_best)\n",
        "print(\"\\nConfusion matrix\\n\", cm, \"\\n\")\n",
        "print(classification_report(binary_true, binary_pred_best,\n",
        "                            target_names=['Non‑Joke (0)', 'Joke (>0)']))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}